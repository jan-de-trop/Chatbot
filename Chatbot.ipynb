{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Advanced_models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f1a80501a33549888c1482643c9aa73f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ddcf0f1107494f30ae9d6d47e13ea533",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_062ff324979545e6b8833d4d156826a6",
              "IPY_MODEL_fa0c20525ce540648e3ea1f7ef204f80"
            ]
          }
        },
        "ddcf0f1107494f30ae9d6d47e13ea533": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "062ff324979545e6b8833d4d156826a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f76fd7de38a1439ba16ca61ddeaadbca",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 87599,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 87599,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a051c563581488cb1830ce59ce48610"
          }
        },
        "fa0c20525ce540648e3ea1f7ef204f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f0688d7be73d4bf9a96cff1e147d0712",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 87599/87599 [01:48&lt;00:00, 806.99ex/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c0ed805aaa554624aafcba6839f31d2d"
          }
        },
        "f76fd7de38a1439ba16ca61ddeaadbca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a051c563581488cb1830ce59ce48610": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0688d7be73d4bf9a96cff1e147d0712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c0ed805aaa554624aafcba6839f31d2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "531d0c28f3934f7e88ca382a32fa127c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d6e655ca30944d048fe0004f37f5f8a8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d8d8b918763a409faddf993fbb530db8",
              "IPY_MODEL_57ee6f11f0c44802a9d3fe0e81beaf61"
            ]
          }
        },
        "d6e655ca30944d048fe0004f37f5f8a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d8d8b918763a409faddf993fbb530db8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_27adb0694cc94a96b0f394836648d2e7",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 10570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a0fa2e2088c4ead82693d5d75512b76"
          }
        },
        "57ee6f11f0c44802a9d3fe0e81beaf61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a3cb12e127064bf0a915e7baf984593c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10570/10570 [00:19&lt;00:00, 528.61ex/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff00cc469c79475aa5fa22b65842ce7a"
          }
        },
        "27adb0694cc94a96b0f394836648d2e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a0fa2e2088c4ead82693d5d75512b76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a3cb12e127064bf0a915e7baf984593c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff00cc469c79475aa5fa22b65842ce7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Surojit-KB/UNIV-AI-AI3_Project/blob/main/Advanced_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAxOwKJ3N41R"
      },
      "source": [
        "# ALBERT(from HuggingFace Transformers) for Text Extraction\n",
        "\n",
        "The abstract from the paper is the following:\n",
        "\n",
        "Increasing model size when pretraining natural language representations often results in improved performance on downstream tasks. However, at some point further model increases become harder due to GPU/TPU memory limitations, longer training times, and unexpected model degradation. To address these problems, we present two parameter-reduction techniques to lower memory consumption and increase the training speed of BERT. Comprehensive empirical evidence shows that our proposed methods lead to models that scale much better compared to the original BERT. We also use a self-supervised loss that focuses on modeling inter-sentence coherence, and show it consistently helps downstream tasks with multi-sentence inputs. As a result, our best model establishes new state-of-the-art results on the GLUE, RACE, and SQuAD benchmarks while having fewer parameters compared to BERT-large.\n",
        "\n",
        "It basically presents two parameter-reduction techniques to lower memory consumption and increase the training speed of BERT:\n",
        "1. Splitting the embedding matrix into two smaller matrices.\n",
        "2. Using repeating layers split among groups.\n",
        "\n",
        "However the computational cost remains similar to a BERT-like architecture with the same number of hidden layers as it has to iterate through the same number of (repeating) layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiomlPG-N41U"
      },
      "source": [
        "## Introduction to Dataset & Training Method\n",
        "\n",
        "The model was first fine-tuned with Stanford Question-Answering Dataset(SQuAD).\n",
        "In SQuAD, an input consists of a question, and a paragraph for context.\n",
        "The goal is to find the span of text in the paragraph that answers the question.\n",
        "We evaluate our performance on this data with the \"Exact Match\" metric,\n",
        "which measures the percentage of predictions that exactly match any one of the\n",
        "ground-truth answers.\n",
        "\n",
        "We fine-tune a ALBERT model to perform this task as follows:\n",
        "\n",
        "1. Feed the context and the question as inputs to ALBERT.\n",
        "2. Take two vectors S and T with dimensions equal to that of\n",
        "   hidden states in ALBERT.\n",
        "3. Compute the probability of each token being the start and end of\n",
        "   the answer span. The probability of a token being the start of\n",
        "   the answer is given by a dot product between S and the representation\n",
        "   of the token in the last layer of ALBERT, followed by a softmax over all tokens.\n",
        "   The probability of a token being the end of the answer is computed\n",
        "   similarly with the vector T.\n",
        "4. Fine-tune ALBERT and learn S and T along the way.\n",
        "\n",
        "**References:**\n",
        "\n",
        "- [ALBERT](https://arxiv.org/abs/1909.11942)\n",
        "- [SQuAD](https://arxiv.org/abs/1606.05250)\n",
        "- [BERT CODE](https://keras.io/examples/nlp/text_extraction_with_bert/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkILnQywN41V"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-otuMksOWGX",
        "outputId": "c4bf0cdf-762f-4443-b8e3-b355ac2e5361"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, \n",
            "and then re-execute this cell.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsxnQAreowEZ",
        "outputId": "157b56a6-ed2b-496f-ca22-18ae80679e6b"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 37.9 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mceIrgjFQr9U",
        "outputId": "c6a38124-29ae-474b-c78b-ed0d66f36301"
      },
      "source": [
        "!pip install tokenizers\n",
        "!pip install transformers\n",
        "!pip install sentence-transformers\n",
        "!pip install sentencepiece\n",
        "!pip install datasets"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.7/dist-packages (0.10.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.9.1+cu101)\n",
            "Requirement already satisfied: transformers<5.0.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.95)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.8.1+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.10.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (4.0.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.0.45)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.0.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.7.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (20.9)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: pyarrow<4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (4.0.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD23c4spN41V"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import string\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "from transformers import AlbertTokenizerFast, TFAlbertModel, AlbertConfig\n",
        "import sentencepiece\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from sentence_transformers import CrossEncoder\n",
        "from transformers import T5TokenizerFast, T5Config, TFT5Model\n",
        "from datasets import load_dataset\n",
        "import datasets\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G47XZ52FvAsT",
        "outputId": "bdc2a73b-3a02-4a98-b9c8-5367d31e0dd9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdImGOdgXaqt"
      },
      "source": [
        "# **Fine Tuning on Squad**\n",
        "\n",
        "1. Good results were achived on the SQuAD dataset, we got an ExactMatch Score of 83 and F1 score of 92."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bF33iKkPpD0P"
      },
      "source": [
        "configuration = AlbertConfig()  # default parameters and configuration for ALBERT"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xau6Sz_LN41X"
      },
      "source": [
        "## Load the Data & Tokenizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpU7_ae1eAon"
      },
      "source": [
        "The data is downloaded first by using the  JSON path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLBbBGGlN41X"
      },
      "source": [
        "train_data_url = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\"\n",
        "train_path = keras.utils.get_file(\"train.json\", train_data_url)\n",
        "eval_data_url = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\"\n",
        "eval_path = keras.utils.get_file(\"eval.json\", eval_data_url)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3e5NH0y65d6x"
      },
      "source": [
        "# The tokenizer is loaded, we used the fast tokenizer from huggingface\n",
        "tokenizer = AlbertTokenizerFast.from_pretrained('albert-large-v2')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS0UaYSeN41X"
      },
      "source": [
        "## Preprocess the data\n",
        "\n",
        "1. Go through the JSON file and store every record as a SquadExample object.\n",
        "2. Go through each SquadExample and create x_train, y_train, x_eval, y_eval.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIz4OklIhKpI"
      },
      "source": [
        "max_len = 384 # The maximum length is set as 384"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fipvmimaN41Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa9c620c-d371-4342-f79f-9ee508545607"
      },
      "source": [
        "# SquadExample class is used for making an object for each question in SQuAD\n",
        "class SquadExample:\n",
        "    def __init__(self, question, context, start_char_idx, answer_text, all_answers):\n",
        "        self.question = question\n",
        "        self.context = context\n",
        "        self.start_char_idx = start_char_idx\n",
        "        self.answer_text = answer_text\n",
        "        self.all_answers = all_answers\n",
        "        self.skip = False\n",
        "\n",
        "    def preprocess(self):\n",
        "        context = self.context\n",
        "        question = self.question\n",
        "        answer_text = self.answer_text\n",
        "        start_char_idx = self.start_char_idx\n",
        "\n",
        "        # Clean context, answer and question\n",
        "        context = \" \".join(str(context).split())\n",
        "        question = \" \".join(str(question).split())\n",
        "        answer = \" \".join(str(answer_text).split())\n",
        "\n",
        "        # Find end character index of answer in context\n",
        "        end_char_idx = start_char_idx + len(answer)\n",
        "        if end_char_idx >= len(context):\n",
        "            self.skip = True\n",
        "            return\n",
        "\n",
        "        # Mark the character indexes in context that are in answer\n",
        "        is_char_in_ans = [0] * len(context)\n",
        "        for idx in range(start_char_idx, end_char_idx):\n",
        "            is_char_in_ans[idx] = 1\n",
        "\n",
        "        # Tokenize context\n",
        "        tokenized_context = tokenizer(context, return_offsets_mapping=True)\n",
        "\n",
        "        # Find tokens that were created from answer characters\n",
        "        ans_token_idx = []\n",
        "        for idx, start_end in enumerate(tokenized_context['offset_mapping']):\n",
        "            start = start_end[0]\n",
        "            end = start_end[1]\n",
        "            if sum(is_char_in_ans[start:end]) > 0:\n",
        "                ans_token_idx.append(idx)\n",
        "\n",
        "        if len(ans_token_idx) == 0:\n",
        "            self.skip = True\n",
        "            return\n",
        "\n",
        "        # Find start and end token index for tokens from answer\n",
        "        start_token_idx = ans_token_idx[0]\n",
        "        end_token_idx = ans_token_idx[-1]\n",
        "\n",
        "        # Tokenize question\n",
        "        tokenized_question = tokenizer(question, return_offsets_mapping=True)\n",
        "\n",
        "        # Create inputs\n",
        "        input_ids = tokenized_context['input_ids'] + tokenized_question['input_ids'][1:]\n",
        "        token_type_ids = [0] * len(tokenized_context['input_ids']) + [1] * len(\n",
        "            tokenized_question['input_ids'][1:]\n",
        "        )\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "\n",
        "        # Pad and create attention masks.\n",
        "        # Skip if truncation is needed\n",
        "        padding_length = max_len - len(input_ids)\n",
        "        if padding_length > 0:  # pad\n",
        "            input_ids = input_ids + ([0] * padding_length)\n",
        "            attention_mask = attention_mask + ([0] * padding_length)\n",
        "            token_type_ids = token_type_ids + ([0] * padding_length)\n",
        "        elif padding_length < 0:  # skip\n",
        "            self.skip = True\n",
        "            return\n",
        "\n",
        "        self.input_ids = input_ids\n",
        "        self.token_type_ids = token_type_ids\n",
        "        self.attention_mask = attention_mask\n",
        "        self.start_token_idx = start_token_idx\n",
        "        self.end_token_idx = end_token_idx\n",
        "        self.context_token_to_char = tokenized_context['offset_mapping']\n",
        "\n",
        "# Training & Validation Data is Loaded\n",
        "with open(train_path) as f:\n",
        "    raw_train_data = json.load(f)\n",
        "\n",
        "with open(eval_path) as f:\n",
        "    raw_eval_data = json.load(f)\n",
        "\n",
        "\n",
        "def create_squad_examples(raw_data):\n",
        "    squad_examples = []\n",
        "    for item in tqdm(raw_data[\"data\"]):\n",
        "        for para in item[\"paragraphs\"]:\n",
        "            context = para[\"context\"]\n",
        "            for qa in para[\"qas\"]:\n",
        "                question = qa[\"question\"]\n",
        "                answer_text = qa[\"answers\"][0][\"text\"]\n",
        "                all_answers = [_[\"text\"] for _ in qa[\"answers\"]]\n",
        "                start_char_idx = qa[\"answers\"][0][\"answer_start\"]\n",
        "                squad_eg = SquadExample(\n",
        "                    question, context, start_char_idx, answer_text, all_answers\n",
        "                )\n",
        "                squad_eg.preprocess()\n",
        "                squad_examples.append(squad_eg)\n",
        "    return squad_examples\n",
        "\n",
        "\n",
        "def create_inputs_targets(squad_examples):\n",
        "    dataset_dict = {\n",
        "        \"input_ids\": [],\n",
        "        \"token_type_ids\": [],\n",
        "        \"attention_mask\": [],\n",
        "        \"start_token_idx\": [],\n",
        "        \"end_token_idx\": [],\n",
        "    }\n",
        "    for item in squad_examples:\n",
        "        if item.skip == False:\n",
        "            for key in dataset_dict:\n",
        "                dataset_dict[key].append(getattr(item, key))\n",
        "    for key in dataset_dict:\n",
        "        dataset_dict[key] = np.array(dataset_dict[key])\n",
        "\n",
        "    x = [\n",
        "        dataset_dict[\"input_ids\"],\n",
        "        dataset_dict[\"token_type_ids\"],\n",
        "        dataset_dict[\"attention_mask\"],\n",
        "    ]\n",
        "    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n",
        "    return x, y\n",
        "\n",
        "\n",
        "train_squad_examples = create_squad_examples(raw_train_data)\n",
        "x_train, y_train = create_inputs_targets(train_squad_examples)\n",
        "print(f\"{len(train_squad_examples)} training points created.\")\n",
        "\n",
        "eval_squad_examples = create_squad_examples(raw_eval_data)\n",
        "x_eval, y_eval = create_inputs_targets(eval_squad_examples)\n",
        "print(f\"{len(eval_squad_examples)} evaluation points created.\")\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  1%|▏         | 6/442 [00:02<02:38,  2.75it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "100%|██████████| 442/442 [01:34<00:00,  4.68it/s]\n",
            "  0%|          | 0/48 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "87599 training points created.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 48/48 [00:11<00:00,  4.24it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "10570 evaluation points created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRmMu0Ej5N5-"
      },
      "source": [
        "## **Model Maker** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94YBp-4RN41a"
      },
      "source": [
        "Create the Question-Answering Model using ALBERT and Functional API\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuwlV89pN41a"
      },
      "source": [
        "\n",
        "def create_model():\n",
        "    ## Pretrained ALBERT encoder\n",
        "    encoder = TFAlbertModel.from_pretrained(\"albert-large-v2\")\n",
        "\n",
        "    ## QA Model\n",
        "    input_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    token_type_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    attention_mask = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    # Getting the Contextual EMbeddings from ALBERT\n",
        "    embedding = encoder(\n",
        "        input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask\n",
        "    )[0]\n",
        "\n",
        "    # Making a model for using the embeddings trained on SQuAD QA when fine-tuning on UNIV-AI1 QA Data\n",
        "    embedding_model = keras.Model(\n",
        "        inputs=[input_ids, token_type_ids, attention_mask],\n",
        "        outputs=embedding,\n",
        "    )\n",
        "\n",
        "    # embedding_model.load_weights('/content/drive/MyDrive/univai/Project/squad_model.h5')\n",
        "\n",
        "    # The probability for identifying the start index of the attention span\n",
        "    start_logits = layers.Dense(1, name=\"start_logit\", use_bias=False)(embedding)\n",
        "    start_logits = layers.Flatten()(start_logits)\n",
        "\n",
        "    # The probability for identifying the end index of the attention span\n",
        "    end_logits = layers.Dense(1, name=\"end_logit\", use_bias=False)(embedding)\n",
        "    end_logits = layers.Flatten()(end_logits)\n",
        "\n",
        "    # Softmax is applied for getting the probabilities\n",
        "    start_probs = layers.Activation(keras.activations.softmax)(start_logits)\n",
        "    end_probs = layers.Activation(keras.activations.softmax)(end_logits)\n",
        "\n",
        "    model = keras.Model(\n",
        "        inputs=[input_ids, token_type_ids, attention_mask],\n",
        "        outputs=[start_probs, end_probs],\n",
        "    )\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "    optimizer = keras.optimizers.Adam(lr=5e-5)\n",
        "    model.compile(optimizer=optimizer, loss=[loss, loss], metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(name='accuracy')])\n",
        "    return model, embedding_model\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPfFxl12N41b"
      },
      "source": [
        "We advise this notebook to be run on Google Colab TPU runtime.\n",
        "With Colab TPUs, each epoch will take 10 minutes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHh8NNtjN41b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9003b81e-a178-45de-993d-42e0f42ab599"
      },
      "source": [
        "use_tpu = True\n",
        "if use_tpu:\n",
        "    # Create distribution strategy\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "    # Create model\n",
        "    with strategy.scope():\n",
        "        model, embedding_model = create_model()\n",
        "else:\n",
        "    model, embedding_model = create_model()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.67.3.2:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.67.3.2:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "Some layers from the model checkpoint at albert-large-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
            "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-large-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fc4cbd6bf30>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fc4cbd6bf30>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fc4cbd6bf30>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fc4e3098dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fc4e3098dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7fc4e3098dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDyRDrYaTnNt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e71c970b-eaa5-49e3-e489-fc99299e7164"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_albert_model (TFAlbertModel) TFBaseModelOutputWit 17683968    input_1[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "start_logit (Dense)             (None, 384, 1)       1024        tf_albert_model[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "end_logit (Dense)               (None, 384, 1)       1024        tf_albert_model[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 384)          0           start_logit[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 384)          0           end_logit[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 384)          0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 384)          0           flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 17,686,016\n",
            "Trainable params: 17,686,016\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gty4nKhtN41c"
      },
      "source": [
        "## Create evaluation Callback\n",
        "\n",
        "This callback will compute the exact match score & F1 score using the validation data\n",
        "after every epoch.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4lcpq-IN41c"
      },
      "source": [
        "from collections import Counter\n",
        "def normalize_answer(s):\n",
        "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "    def remove_articles(text):\n",
        "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return ''.join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "def f1_score_fn(prediction_tokens, ground_truth_tokens):\n",
        "    # prediction_tokens = normalize_answer(prediction).split()\n",
        "    # ground_truth_tokens = normalize_answer(ground_truth).split()\n",
        "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "    precision = 1.0 * num_same / len(prediction_tokens)\n",
        "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "# Iterating over each possible answer and finding if any of our predictions match\n",
        "def intermediate_for_f1(metric_fn, prediction, ground_truths):\n",
        "    scores_for_ground_truths = []\n",
        "    for ground_truth in ground_truths:\n",
        "        score = metric_fn(prediction, ground_truth)\n",
        "        scores_for_ground_truths.append(score)\n",
        "    return max(scores_for_ground_truths)\n",
        "\n",
        "class ExactMatch(keras.callbacks.Callback):\n",
        "    \"\"\"\n",
        "    Each `SquadExample` object contains the character level offsets for each token\n",
        "    in its input paragraph. We use them to get back the span of text corresponding\n",
        "    to the tokens between our predicted start and end tokens.\n",
        "    All the ground-truth answers are also present in each `SquadExample` object.\n",
        "    We calculate the percentage of data points where the span of text obtained\n",
        "    from model predictions matches one of the ground-truth answers.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, x_eval, y_eval):\n",
        "        self.x_eval = x_eval\n",
        "        self.y_eval = y_eval\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        pred_start, pred_end = self.model.predict(self.x_eval)\n",
        "        count = 0\n",
        "        f1_score = 0\n",
        "        eval_examples_no_skip = [_ for _ in eval_squad_examples if _.skip == False]\n",
        "        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
        "            squad_eg = eval_examples_no_skip[idx]\n",
        "            offsets = squad_eg.context_token_to_char\n",
        "            start = np.argmax(start)\n",
        "            end = np.argmax(end)\n",
        "            if start >= len(offsets):\n",
        "                continue\n",
        "            pred_char_start = offsets[start][0]\n",
        "            if end < len(offsets):\n",
        "                pred_char_end = offsets[end][1]\n",
        "                pred_ans = squad_eg.context[pred_char_start:pred_char_end]\n",
        "            else:\n",
        "                pred_ans = squad_eg.context[pred_char_start:]\n",
        "\n",
        "            normalized_pred_ans = normalize_answer(pred_ans)\n",
        "            normalized_true_ans = [normalize_answer(_) for _ in squad_eg.all_answers]\n",
        "            f1_score += intermediate_for_f1(f1_score_fn, normalized_pred_ans, normalized_true_ans)\n",
        "            if normalized_pred_ans in normalized_true_ans:\n",
        "                count += 1\n",
        "        acc = count / len(self.y_eval[0])\n",
        "        f1_score = f1_score / len(self.y_eval[0])\n",
        "        print(f\"\\nepoch={epoch+1}, exact match score={acc:.2f}, f1 score={f1_score:.2f}\")\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wRExDpBN41d"
      },
      "source": [
        "## Train and Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ar0yG8hoN41d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24493e61-2be0-404c-e9a9-cfa796e04ef6"
      },
      "source": [
        "exact_match_callback = ExactMatch(x_eval, y_eval)\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=3,  # For demonstration, 3 epochs are recommended\n",
        "    verbose=1,\n",
        "    batch_size=64,\n",
        "    callbacks=[exact_match_callback],\n",
        ")\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None,) dtype=int64>, <tf.Tensor 'cond_8/Identity_4:0' shape=(None,) dtype=int64>]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss.\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None,) dtype=int64>, <tf.Tensor 'cond_8/Identity_4:0' shape=(None,) dtype=int64>]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   6/1345 [..............................] - ETA: 10:07 - loss: 9.4876 - activation_loss: 4.8990 - activation_1_loss: 4.5886 - activation_accuracy: 0.2109 - activation_1_accuracy: 0.2292WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_train_batch_end` time: 8.9593s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_train_batch_end` time: 8.9593s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1345/1345 [==============================] - 736s 484ms/step - loss: 2.0276 - activation_loss: 1.0797 - activation_1_loss: 0.9480 - activation_accuracy: 0.9271 - activation_1_accuracy: 0.9403\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 384) dtype=int64>]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "epoch=1, exact match score=0.82, f1 score=0.92\n",
            "Epoch 2/3\n",
            "1345/1345 [==============================] - 610s 453ms/step - loss: 1.4961 - activation_loss: 0.8052 - activation_1_loss: 0.6909 - activation_accuracy: 0.9619 - activation_1_accuracy: 0.9713\n",
            "\n",
            "epoch=2, exact match score=0.83, f1 score=0.92\n",
            "Epoch 3/3\n",
            "1345/1345 [==============================] - 610s 453ms/step - loss: 1.5308 - activation_loss: 0.8233 - activation_1_loss: 0.7076 - activation_accuracy: 0.9592 - activation_1_accuracy: 0.9695\n",
            "\n",
            "epoch=3, exact match score=0.82, f1 score=0.92\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc180dbb290>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNM0SMxCXJjk"
      },
      "source": [
        "embedding_model.save_weights('/content/drive/MyDrive/univai/Project/squad_model.h5')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rypIijAzhveQ"
      },
      "source": [
        "model.save_weights('/content/drive/MyDrive/univai/Project/squad_whole_model.h5')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX8YTmhNgLBa"
      },
      "source": [
        "# **Fine Tuning on UNIV AI Dataset With Manually Added Context**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IGtZOW9kPQQ"
      },
      "source": [
        "1. For fine-tuning the ALBERT model on the small UNIV-AI dataset we'll be initializing the weights for the ALBERT embeddings from the above trained SQuAD model and freeze them, only the dense layer for getting the probabilities of start and end token is trained.\n",
        "2. The context for each question was mapped manually for this section, an automated method will be dsicussed in the coming sections\n",
        "3. Good results were achieved with the manually mapped context. The csv file can by accesses by -[LINK](https://drive.google.com/file/d/1-c-sf5EwBGA1B7uIc23Ly2G1Dn5Ky5H9/view?usp=sharing)\n",
        "4. The ddataset after manually adding the context can be found here -[Train_Dataset](https://drive.google.com/file/d/1DwbxitPg86Q9pMwSg2h4q2PvO7ogWJ6_/view?usp=sharing), -[Test_Dataset](https://drive.google.com/file/d/1U8Z3cCWfK27P2alSYLxp8MdlsWh9y6EM/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWYoJD1NpGVB"
      },
      "source": [
        "configuration = AlbertConfig()  # default parameters and configuration for ALBERT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZtj5W4BgLBd"
      },
      "source": [
        "## Load the Data & Tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFIddtLUXnyx"
      },
      "source": [
        "# Your code here\n",
        "def clean_data(data):\n",
        "    message_list = data\n",
        "    for i in range(len(message_list)):\n",
        "        # Lower Case\n",
        "        message = message_list[i].lower()\n",
        "\n",
        "        message = \" \".join([word for word in message.split() if word.find('yes') == -1])\n",
        "        message = \" \".join([word for word in message.split() if word.find('no') == -1])\n",
        "        \n",
        "        message = \" \".join(message.split())\n",
        "\n",
        "        message_list[i] = message\n",
        "\n",
        "    return message_list"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEdpKSxAgLBd"
      },
      "source": [
        "# Loading the training data including the manually added context\n",
        "df_con = pd.read_csv('/content/drive/MyDrive/univai/Project/faq_context.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "BUg-6A5APmeZ",
        "outputId": "a1e0fc19-2e27-4152-e490-25dc456d92aa"
      },
      "source": [
        "df_con.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Title</th>\n",
              "      <th>Context</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Pre-class</td>\n",
              "      <td>The course schedule may include readings in th...</td>\n",
              "      <td>Are session pre-class quizzes graded?</td>\n",
              "      <td>No. Pre-class quiz is to just check your under...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Deadlines</td>\n",
              "      <td>The exercises that you worked on during the ma...</td>\n",
              "      <td>When is the deadline for the submission of ses...</td>\n",
              "      <td>5 PM on the day of the following lecture.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Deadlines</td>\n",
              "      <td>The exercises that you worked on during the ma...</td>\n",
              "      <td>Will there be any extension allowed for the qu...</td>\n",
              "      <td>Only for exceptional cases.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Amount of work</td>\n",
              "      <td>Our courses need a time commitment of about 15...</td>\n",
              "      <td>How many hours will I need to dedicate to succ...</td>\n",
              "      <td>About 15 hours per week.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Exercise grading</td>\n",
              "      <td>We conduct both group and individual evaluatio...</td>\n",
              "      <td>Who will grade my exercise?</td>\n",
              "      <td>The exercises are auto-graded once you click t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0             Title  ... Unnamed: 2 Unnamed: 3\n",
              "0           0         Pre-class  ...        NaN        NaN\n",
              "1           1         Deadlines  ...        NaN        NaN\n",
              "2           2         Deadlines  ...        NaN        NaN\n",
              "3           3    Amount of work  ...        NaN        NaN\n",
              "4           4  Exercise grading  ...        NaN        NaN\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcc1a8hbUX-a"
      },
      "source": [
        "# Getting the Context, Question & Answer in a list. Then cleaning them\n",
        "questions_list = df_con.Question.tolist()\n",
        "clean_questions = clean_data(questions_list)\n",
        "\n",
        "answer_list = df_con.Answer.tolist()\n",
        "clean_answers = clean_data(answer_list)\n",
        "\n",
        "context_list = df_con.Context.tolist()\n",
        "clean_context = clean_data(context_list)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsfBJy3MWHPX"
      },
      "source": [
        "# Finding the start index for the answer in the context, if not found ind is set at 0\n",
        "start_indexes = []\n",
        "for context, answer in zip(clean_context, clean_answers):\n",
        "  ind = context.find(answer[:20])\n",
        "  if ind == -1:\n",
        "    ind = context.find(answer[:5])\n",
        "  if ind == -1:\n",
        "    ind = 0\n",
        "  start_indexes.append(ind)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMnvJnkhFC_D"
      },
      "source": [
        "# Loading the test dataset with the manually added context\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/univai/Project/test_manual.csv')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "IkpP0fcnFFuH",
        "outputId": "d834f501-af06-44ce-c737-1e5b08b79b03"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Questions</th>\n",
              "      <th>Context</th>\n",
              "      <th>start_idx</th>\n",
              "      <th>end_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Will the pre-class session be recorded?</td>\n",
              "      <td>The course schedule may include readings in th...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the deadline for quiz submission?</td>\n",
              "      <td>The exercises that you worked on during the ma...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the deadline for exercise submission?</td>\n",
              "      <td>The exercises that you worked on during the ma...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How many hours do I need to complete this course?</td>\n",
              "      <td>Our courses need a time commitment of about 15...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Who will grade the exercise?</td>\n",
              "      <td>We conduct both group and individual evaluatio...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Questions  ... end_idx\n",
              "0            Will the pre-class session be recorded?  ...       2\n",
              "1          What is the deadline for quiz submission?  ...       2\n",
              "2      What is the deadline for exercise submission?  ...       2\n",
              "3  How many hours do I need to complete this course?  ...       2\n",
              "4                       Who will grade the exercise?  ...       2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UXMSQ-zFJTg"
      },
      "source": [
        "# Getting the Context, Question & Answer in a list. Then cleaning them\n",
        "val_questions = df_test.Questions.tolist()\n",
        "val_questions = clean_data(val_questions)\n",
        "\n",
        "val_answers = ['No Provided Answer']*len(val_questions) # Dummy Answer for ease of uniform preprocessing\n",
        "\n",
        "val_context = df_test.Context.tolist()\n",
        "val_context = clean_data(val_context)\n",
        "\n",
        "# Dummy start_idx for ease of uniform preprocessing\n",
        "val_start_idx = df_test.start_idx.tolist()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8tm2kAbgLBe"
      },
      "source": [
        "# Tokenizer is loaded\n",
        "tokenizer = AlbertTokenizerFast.from_pretrained('albert-large-v2')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOootpX5gLBf"
      },
      "source": [
        "## Preprocess the data\n",
        "\n",
        "1. Go through the JSON file and store every record as a SquadExample object.\n",
        "2. Go through each SquadExample and create x_train, y_train, x_eval, y_eval.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrPhGHI2meXt"
      },
      "source": [
        "max_len = 384 # The maximum length is set as 384"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XshlmQkvgLBf",
        "outputId": "3321f350-9970-4531-dc17-86bcd4f4946b"
      },
      "source": [
        "# SquadExample class is used for making an object for each question in SQuAD\n",
        "class SquadExample:\n",
        "    def __init__(self, question, context, start_char_idx, answer_text):\n",
        "        self.question = question\n",
        "        self.context = context\n",
        "        self.start_char_idx = start_char_idx\n",
        "        self.answer_text = answer_text\n",
        "        self.skip = False\n",
        "\n",
        "    def preprocess(self):\n",
        "        context = self.context\n",
        "        question = self.question\n",
        "        answer_text = self.answer_text\n",
        "        start_char_idx = self.start_char_idx\n",
        "\n",
        "        # Clean context, answer and question\n",
        "        context = \" \".join(str(context).split())\n",
        "        question = \" \".join(str(question).split())\n",
        "        answer = \" \".join(str(answer_text).split())\n",
        "\n",
        "        # Find end character index of answer in context\n",
        "        end_char_idx = start_char_idx + len(answer)\n",
        "        if end_char_idx >= len(context):\n",
        "            self.skip = True\n",
        "            return\n",
        "\n",
        "        # Mark the character indexes in context that are in answer\n",
        "        is_char_in_ans = [0] * len(context)\n",
        "        for idx in range(start_char_idx, end_char_idx):\n",
        "            is_char_in_ans[idx] = 1\n",
        "\n",
        "        # Tokenize context\n",
        "        tokenized_context = tokenizer(context, return_offsets_mapping=True)\n",
        "\n",
        "        # Find tokens that were created from answer characters\n",
        "        ans_token_idx = []\n",
        "        for idx, start_end in enumerate(tokenized_context['offset_mapping']):\n",
        "            start = start_end[0]\n",
        "            end = start_end[1]\n",
        "            if sum(is_char_in_ans[start:end]) > 0:\n",
        "                ans_token_idx.append(idx)\n",
        "\n",
        "        if len(ans_token_idx) == 0:\n",
        "            self.skip = True\n",
        "            return\n",
        "\n",
        "        # Find start and end token index for tokens from answer\n",
        "        start_token_idx = ans_token_idx[0]\n",
        "        end_token_idx = ans_token_idx[-1]\n",
        "\n",
        "        # Tokenize question\n",
        "        tokenized_question = tokenizer(question, return_offsets_mapping=True)\n",
        "\n",
        "        # Create inputs\n",
        "        input_ids = tokenized_context['input_ids'] + tokenized_question['input_ids'][1:]\n",
        "        token_type_ids = [0] * len(tokenized_context['input_ids']) + [1] * len(\n",
        "            tokenized_question['input_ids'][1:]\n",
        "        )\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "\n",
        "        # Pad and create attention masks.\n",
        "        # Skip if truncation is needed\n",
        "        padding_length = max_len - len(input_ids)\n",
        "        if padding_length > 0:  # pad\n",
        "            input_ids = input_ids + ([0] * padding_length)\n",
        "            attention_mask = attention_mask + ([0] * padding_length)\n",
        "            token_type_ids = token_type_ids + ([0] * padding_length)\n",
        "        elif padding_length < 0:  # skip\n",
        "            self.skip = True\n",
        "            return\n",
        "\n",
        "        self.input_ids = input_ids\n",
        "        self.token_type_ids = token_type_ids\n",
        "        self.attention_mask = attention_mask\n",
        "        self.start_token_idx = start_token_idx\n",
        "        self.end_token_idx = end_token_idx\n",
        "        self.context_token_to_char = tokenized_context['offset_mapping']\n",
        "\n",
        "\n",
        "def create_squad_examples(clean_questions, clean_context, clean_answers, start_indexes):\n",
        "    squad_examples = []\n",
        "   \n",
        "    for ques, cont, ans, idx in zip(clean_questions, clean_context, clean_answers, start_indexes):\n",
        "      question = ques\n",
        "      context = cont\n",
        "      answer_text = ans\n",
        "      start_char_idx = idx\n",
        "      squad_eg = SquadExample(\n",
        "          question, context, start_char_idx, answer_text\n",
        "      )\n",
        "      squad_eg.preprocess()\n",
        "      squad_examples.append(squad_eg)\n",
        "    return squad_examples\n",
        "\n",
        "\n",
        "def create_inputs_targets(squad_examples):\n",
        "    dataset_dict = {\n",
        "        \"input_ids\": [],\n",
        "        \"token_type_ids\": [],\n",
        "        \"attention_mask\": [],\n",
        "        \"start_token_idx\": [],\n",
        "        \"end_token_idx\": [],\n",
        "    }\n",
        "    for item in squad_examples:\n",
        "        if item.skip == False:\n",
        "            for key in dataset_dict:\n",
        "                dataset_dict[key].append(getattr(item, key))\n",
        "    for key in dataset_dict:\n",
        "        dataset_dict[key] = np.array(dataset_dict[key])\n",
        "\n",
        "    x = [\n",
        "        dataset_dict[\"input_ids\"],\n",
        "        dataset_dict[\"token_type_ids\"],\n",
        "        dataset_dict[\"attention_mask\"],\n",
        "    ]\n",
        "    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n",
        "    return x, y\n",
        "\n",
        "\n",
        "train_squad_examples = create_squad_examples(clean_questions, clean_context, clean_answers, start_indexes)\n",
        "x_train, y_train = create_inputs_targets(train_squad_examples)\n",
        "print(f\"{len(train_squad_examples)} training points created.\")\n",
        "\n",
        "eval_squad_examples = create_squad_examples(val_questions, val_context, val_answers, val_start_idx)\n",
        "x_eval, y_eval = create_inputs_targets(eval_squad_examples)\n",
        "print(f\"{len(eval_squad_examples)} evaluation points created.\")\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33 training points created.\n",
            "24 evaluation points created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQ6BR19dgLBf"
      },
      "source": [
        "## **Model Maker** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2llTZSR4gLBf"
      },
      "source": [
        "Create the Question-Answering Model using ALBERT and Functional API\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yowTw4jHgLBg"
      },
      "source": [
        "\n",
        "def create_model():\n",
        "    ## Pretrained ALBERT encoder\n",
        "    encoder = TFAlbertModel.from_pretrained(\"albert-large-v2\")\n",
        "\n",
        "    ## QA Model\n",
        "    input_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    token_type_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    attention_mask = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    # Getting the Contextual EMbeddings from ALBERT\n",
        "    embedding = encoder(\n",
        "        input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask\n",
        "    )[0]\n",
        "\n",
        "    # Initializing the embedding of ALBERT from the fine-tuned weights of SQuAD\n",
        "    embedding_model = keras.Model(\n",
        "        inputs=[input_ids, token_type_ids, attention_mask],\n",
        "        outputs=embedding,\n",
        "    )\n",
        "\n",
        "    embedding_model.load_weights('/content/drive/MyDrive/univai/Project/squad_model.h5')\n",
        "\n",
        "    # The probability for identifying the start index of the attention span\n",
        "    start_logits = layers.Dense(1, name=\"start_logit\", use_bias=False)(embedding)\n",
        "    start_logits = layers.Flatten()(start_logits)\n",
        "\n",
        "    # The probability for identifying the end index of the attention span\n",
        "    end_logits = layers.Dense(1, name=\"end_logit\", use_bias=False)(embedding)\n",
        "    end_logits = layers.Flatten()(end_logits)\n",
        "\n",
        "    # Softmax is applied for getting the probabilities\n",
        "    start_probs = layers.Activation(keras.activations.softmax)(start_logits)\n",
        "    end_probs = layers.Activation(keras.activations.softmax)(end_logits)\n",
        "\n",
        "    model = keras.Model(\n",
        "        inputs=[input_ids, token_type_ids, attention_mask],\n",
        "        outputs=[start_probs, end_probs],\n",
        "    )\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "    optimizer = keras.optimizers.Adam(lr=5e-5)\n",
        "    model.compile(optimizer=optimizer, loss=[loss, loss], metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(name='accuracy')])\n",
        "    # model.load_weights('/content/drive/MyDrive/univai/Project/squad_whole_model.h5')\n",
        "    return model, embedding_model\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E27V5HytgLBg"
      },
      "source": [
        "We advise this notebook to be run on Google Colab TPU runtime.\n",
        "With Colab TPUs, each epoch will take 1 second.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b02GNW7gLBg",
        "outputId": "ad2e18b6-7ab7-4037-8633-0b4da906d546"
      },
      "source": [
        "use_tpu = True\n",
        "if use_tpu:\n",
        "    # Create distribution strategy\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "    # Create model\n",
        "    with strategy.scope():\n",
        "        model, embedding_model = create_model()\n",
        "else:\n",
        "    model, embedding_model = create_model()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.78.167.202:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.78.167.202:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "Some layers from the model checkpoint at albert-large-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
            "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-large-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7ff1f26a5e50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7ff1f26a5e50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7ff1f26a5e50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7ff2092a5dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7ff2092a5dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7ff2092a5dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl8ZNRCKgLBg",
        "outputId": "4a74b4e2-a832-4fbc-b43d-e422fbbf3383"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_albert_model (TFAlbertModel) TFBaseModelOutputWit 17683968    input_1[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "start_logit (Dense)             (None, 384, 1)       1024        tf_albert_model[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "end_logit (Dense)               (None, 384, 1)       1024        tf_albert_model[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 384)          0           start_logit[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 384)          0           end_logit[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 384)          0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 384)          0           flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 17,686,016\n",
            "Trainable params: 17,686,016\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65IUECwtgLBh"
      },
      "source": [
        "#For fine-tuning the ALBERT model on the small UNIV-AI dataset we'll be initializing the weights for the ALBERT embeddings from the \n",
        "#above trained SQuAD model and freeze them, only the dense layer for getting the probabilities of start and end token is trained.\n",
        "albert_layer = model.get_layer('tf_albert_model')\n",
        "albert_layer.trainable = False"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOZ7nvBRgLBh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b960870f-f038-4edb-c0b0-f97c5eca05cc"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_albert_model (TFAlbertModel) TFBaseModelOutputWit 17683968    input_1[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "start_logit (Dense)             (None, 384, 1)       1024        tf_albert_model[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "end_logit (Dense)               (None, 384, 1)       1024        tf_albert_model[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 384)          0           start_logit[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 384)          0           end_logit[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 384)          0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 384)          0           flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 17,686,016\n",
            "Trainable params: 2,048\n",
            "Non-trainable params: 17,683,968\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPnS73rMgLBh"
      },
      "source": [
        "## Create evaluation Callback\n",
        "\n",
        "This callback will will save the a CSV file containing the question and it's predicted answer for each epoch.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLAgHfR9gLBh"
      },
      "source": [
        "from collections import Counter\n",
        "def normalize_text(text):\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuations\n",
        "    exclude = set(string.punctuation)\n",
        "    text = \"\".join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    # Remove articles\n",
        "    regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "    text = re.sub(regex, \" \", text)\n",
        "\n",
        "    # Remove extra white space\n",
        "    text = \" \".join(text.split())\n",
        "    return text\n",
        "\n",
        "\n",
        "class Predicted_Ans(keras.callbacks.Callback):\n",
        "\n",
        "    def __init__(self, x_eval, y_eval):\n",
        "        self.x_eval = x_eval\n",
        "        self.y_eval = y_eval\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        pred_start, pred_end = self.model.predict(self.x_eval)\n",
        "        count = 0\n",
        "        predicted_answers = []\n",
        "        questions = []\n",
        "        eval_examples_no_skip = [_ for _ in eval_squad_examples if _.skip == False]\n",
        "        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
        "            squad_eg = eval_examples_no_skip[idx]\n",
        "            offsets = squad_eg.context_token_to_char\n",
        "            start = np.argmax(start)\n",
        "            end = np.argmax(end)\n",
        "            if start >= len(offsets):\n",
        "                continue\n",
        "            pred_char_start = offsets[start][0]\n",
        "            if end < len(offsets):\n",
        "                pred_char_end = offsets[end][1]\n",
        "                pred_ans = squad_eg.context[pred_char_start:pred_char_end]\n",
        "            else:\n",
        "                pred_ans = squad_eg.context[pred_char_start:]\n",
        "\n",
        "            normalized_pred_ans = normalize_text(pred_ans)\n",
        "\n",
        "            questions.append(normalize_text(squad_eg.question))\n",
        "            predicted_answers.append(normalized_pred_ans)\n",
        "\n",
        "        df_dict = {'Question' : questions, 'Answer' : predicted_answers}\n",
        "        df = pd.DataFrame(df_dict, columns=['Question','Answer'])\n",
        "        if epoch%1 == 0:\n",
        "          df.to_csv('/content/drive/MyDrive/univai/Project/Univ_pred/manual_predicted_albert' + str(epoch) + '.csv', index=False)\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV_KpAmQgLBh"
      },
      "source": [
        "## Train and Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9K5u1tLgLBi",
        "outputId": "4e02e0ca-1d56-4f04-ae2a-d1bc8193c0f4"
      },
      "source": [
        "predicted_answers = Predicted_Ans(x_eval, y_eval)\n",
        "num_epochs = 5\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=num_epochs,  # For demonstration, 3 epochs are recommended\n",
        "    verbose=1,\n",
        "    batch_size=33,\n",
        "    callbacks=[predicted_answers],\n",
        ")\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None,) dtype=int64>, <tf.Tensor 'cond_8/Identity_4:0' shape=(None,) dtype=int64>]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss.\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None,) dtype=int64>, <tf.Tensor 'cond_8/Identity_4:0' shape=(None,) dtype=int64>]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 77s 77s/step - loss: 11.9293 - activation_loss: 6.1506 - activation_1_loss: 5.7787 - activation_accuracy: 0.0000e+00 - activation_1_accuracy: 0.0952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 384) dtype=int64>]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 6.4023 - activation_loss: 3.4005 - activation_1_loss: 3.0019 - activation_accuracy: 0.9048 - activation_1_accuracy: 0.8095\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 3.7685 - activation_loss: 1.8797 - activation_1_loss: 1.8888 - activation_accuracy: 0.9524 - activation_1_accuracy: 0.8571\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 2.2025 - activation_loss: 1.0166 - activation_1_loss: 1.1859 - activation_accuracy: 0.9524 - activation_1_accuracy: 0.9048\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 1.5125 - activation_loss: 0.5620 - activation_1_loss: 0.9505 - activation_accuracy: 1.0000 - activation_1_accuracy: 0.9048\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fef41814c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T_Ot6W2gLBi"
      },
      "source": [
        "# embedding_model.save_weights('/content/drive/MyDrive/univai/Project/Univ_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNmMVAqbgLBi"
      },
      "source": [
        "# model.save_weights('/content/drive/MyDrive/univai/Project/Univ_whole_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "foBoYvhFdxQe",
        "outputId": "0e9106b1-99ae-4b3c-e4a1-9eb662101f63"
      },
      "source": [
        "df_univ_qa = pd.read_csv('/content/drive/MyDrive/univai/Project/Univ_pred/manual_predicted_albert4.csv')\n",
        "df_univ_qa"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>will preclass session be recorded</td>\n",
              "      <td>preclass quiz is to just check your understand...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what is deadline for quiz submission</td>\n",
              "      <td>5 pm on day of following lecture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what is deadline for exercise submission</td>\n",
              "      <td>5 pm on day of following lecture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>how many hours do i need to complete this course</td>\n",
              "      <td>15 hours per week</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>who will grade exercise</td>\n",
              "      <td>exercises are autograded once you click submit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>why is autograder failing me</td>\n",
              "      <td>autograder does accept alternative solutions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>do i do exercises individually</td>\n",
              "      <td>students submit exercises individually but you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>is lab compulsory</td>\n",
              "      <td>labs are compulsory</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>will sessions be recorded</td>\n",
              "      <td>all sessions will be recorded</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>can i have access to recorded videos</td>\n",
              "      <td>all ai1 students have access to livestreaming ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>where are recordings</td>\n",
              "      <td>recording links will be posted on edstem</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>where can i ask questions regarding reading ma...</td>\n",
              "      <td>you can pose questions regarding reading mater...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>where to find course material</td>\n",
              "      <td>all material is available on edstem</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>do we have homework</td>\n",
              "      <td>each session has exercise and there is homewor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>where can i find homework</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>where to submit homework</td>\n",
              "      <td>you and your partner are required to submit ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>where do i find homework</td>\n",
              "      <td>edstem lessons tab</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>where do i submit my homework assignment</td>\n",
              "      <td>you and your partner are required to submit ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>will professor take office hours</td>\n",
              "      <td>your tas will take office hours</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>what is oh zoom link</td>\n",
              "      <td>please check course information slide</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>what will we do in projects</td>\n",
              "      <td>significant part of this course is group proje...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>what should be duration of presentation video</td>\n",
              "      <td>5 minute video along with slides and jupyter w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>do i need to submit project in group</td>\n",
              "      <td>you should submit 5 minute video along with sl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>does attendance count to grading</td>\n",
              "      <td>small component of grading is allocated to cla...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Question                                             Answer\n",
              "0                   will preclass session be recorded  preclass quiz is to just check your understand...\n",
              "1                what is deadline for quiz submission                   5 pm on day of following lecture\n",
              "2            what is deadline for exercise submission                   5 pm on day of following lecture\n",
              "3    how many hours do i need to complete this course                                  15 hours per week\n",
              "4                             who will grade exercise  exercises are autograded once you click submit...\n",
              "5                        why is autograder failing me       autograder does accept alternative solutions\n",
              "6                      do i do exercises individually  students submit exercises individually but you...\n",
              "7                                   is lab compulsory                                labs are compulsory\n",
              "8                           will sessions be recorded                      all sessions will be recorded\n",
              "9                can i have access to recorded videos  all ai1 students have access to livestreaming ...\n",
              "10                               where are recordings           recording links will be posted on edstem\n",
              "11  where can i ask questions regarding reading ma...  you can pose questions regarding reading mater...\n",
              "12                      where to find course material                all material is available on edstem\n",
              "13                                do we have homework  each session has exercise and there is homewor...\n",
              "14                          where can i find homework                                                NaN\n",
              "15                           where to submit homework  you and your partner are required to submit ho...\n",
              "16                           where do i find homework                                 edstem lessons tab\n",
              "17           where do i submit my homework assignment  you and your partner are required to submit ho...\n",
              "18                   will professor take office hours                    your tas will take office hours\n",
              "19                               what is oh zoom link              please check course information slide\n",
              "20                        what will we do in projects  significant part of this course is group proje...\n",
              "21      what should be duration of presentation video  5 minute video along with slides and jupyter w...\n",
              "22               do i need to submit project in group  you should submit 5 minute video along with sl...\n",
              "23                   does attendance count to grading  small component of grading is allocated to cla..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVFGqmu7dzkr"
      },
      "source": [
        "# **Fine Tuning on UNIV AI Data with Automatically Extracted Context**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGEmq9d_pV21"
      },
      "source": [
        "1. For fine-tuning the ALBERT model on the small UNIV-AI dataset we'll be initializing the weights for the ALBERT embeddings from the above trained SQuAD model and freeze them, only the dense layer for getting the probabilities of start and end token is trained.\n",
        "2. **The context for each question was found using a pre-trained Cross-Encoder Trasnformer model by [Sentence Transformer Library](https://www.sbert.net/docs/pretrained_cross-encoders.html), which was pre-trained on the MS Marco Dataset for finding the context paragraph for each question. This pretrained model meets our requirement here perfectly, furthermore in the future if enough data of UNIV-AI corpus is retrieved then we can finetuned this cross encoder on it for better results and use the whole framework of Retrieve & ReRank i.e Bi-Encoder for Retrieving & Cross-Encoder for ReRanking.**\n",
        "3. Overall decent results were achived, but not better than the manually mapped contexts. The csv file can by accesses by -[LINK](https://drive.google.com/file/d/10EeqBlmS9iKW-QsL_quw9-ZmIgCnxO8V/view?usp=sharing)\n",
        "\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SgyDdjQpHlB"
      },
      "source": [
        "configuration = AlbertConfig()  # default parameters and configuration for ALBERT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMGYHgs2eyjs"
      },
      "source": [
        "## **Context Extraction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHZqvQKifb33"
      },
      "source": [
        "# Your code here\n",
        "def clean_data(data):\n",
        "    message_list = data\n",
        "    for i in range(len(message_list)):\n",
        "        # Lower Case\n",
        "        message = message_list[i].lower()\n",
        "\n",
        "        # message = \" \".join([word for word in message.split() if word.find('yes') == -1])\n",
        "        # message = \" \".join([word for word in message.split() if word.find('no') == -1])\n",
        "        \n",
        "        message = \" \".join(message.split())\n",
        "\n",
        "        message_list[i] = message\n",
        "\n",
        "    return message_list"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9oMY5BefP_j"
      },
      "source": [
        "### **Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwGhUiVyfb35"
      },
      "source": [
        "df_con = pd.read_csv('/content/drive/MyDrive/univai/Project/faq_context.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "txIvI88CfPFo",
        "outputId": "27fc7649-fd3b-4e18-c0f1-e833f1f796b3"
      },
      "source": [
        "df_con.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Title</th>\n",
              "      <th>Context</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Pre-class</td>\n",
              "      <td>The course schedule may include readings in th...</td>\n",
              "      <td>Are session pre-class quizzes graded?</td>\n",
              "      <td>No. Pre-class quiz is to just check your under...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Deadlines</td>\n",
              "      <td>The exercises that you worked on during the ma...</td>\n",
              "      <td>When is the deadline for the submission of ses...</td>\n",
              "      <td>5 PM on the day of the following lecture.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Deadlines</td>\n",
              "      <td>The exercises that you worked on during the ma...</td>\n",
              "      <td>Will there be any extension allowed for the qu...</td>\n",
              "      <td>Only for exceptional cases.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Amount of work</td>\n",
              "      <td>Our courses need a time commitment of about 15...</td>\n",
              "      <td>How many hours will I need to dedicate to succ...</td>\n",
              "      <td>About 15 hours per week.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Exercise grading</td>\n",
              "      <td>We conduct both group and individual evaluatio...</td>\n",
              "      <td>Who will grade my exercise?</td>\n",
              "      <td>The exercises are auto-graded once you click t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0             Title  ... Unnamed: 2 Unnamed: 3\n",
              "0           0         Pre-class  ...        NaN        NaN\n",
              "1           1         Deadlines  ...        NaN        NaN\n",
              "2           2         Deadlines  ...        NaN        NaN\n",
              "3           3    Amount of work  ...        NaN        NaN\n",
              "4           4  Exercise grading  ...        NaN        NaN\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkDf1ISDfIVk"
      },
      "source": [
        "# The possibel contexts\n",
        "contexts = df_con.Context.tolist()\n",
        "contexts = clean_data(contexts)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVrWa-V5fK2M"
      },
      "source": [
        "train_questions = df_con.Question.tolist()\n",
        "train_questions = clean_data(train_questions)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-DzZod4fK4Y"
      },
      "source": [
        "train_answers = df_con.Answer.tolist()\n",
        "train_answers = clean_data(train_answers)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQRcBXn_fK7B"
      },
      "source": [
        "# The pretrained cross encoder model is loaded, with maximum length set at 512\n",
        "model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2', max_length=512)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FFE5PJSfLdF"
      },
      "source": [
        "# The score is found for each question against each context vector, the highest score context vector is chosen then for that question.\n",
        "train_contexts = []\n",
        "for question in train_questions:\n",
        "  que_cont = [(question, text) for text in contexts]\n",
        "  scores = model.predict(que_cont)\n",
        "  ind = np.argmax(scores)\n",
        "  train_contexts.append(contexts[ind])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARehHl3xiV6x"
      },
      "source": [
        "# Finding the start index for the answer if available in the context, , if not found ind is set at 0\n",
        "train_start_indexes = []\n",
        "no_ans = 0\n",
        "for context, answer in zip(train_contexts, train_answers):\n",
        "  ind = context.find(answer[:20])\n",
        "  if ind == -1:\n",
        "    ind = context.find(answer[:5])\n",
        "  if ind == -1:\n",
        "    ind = 0\n",
        "    no_ans += 1\n",
        "  train_start_indexes.append(ind)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBc7Hr8-kwjr",
        "outputId": "38158706-b58e-4831-e748-cba63d6c29b3"
      },
      "source": [
        "# Number of questions out of 33 of whom we coudnt find the answer start idx in the automatically found context\n",
        "no_ans"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxuUx_o8ilQT"
      },
      "source": [
        "### **Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHnkz9toitv_"
      },
      "source": [
        "import pandas as pd\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/univai/Project/test_manual.csv')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "PlrexE_JitwA",
        "outputId": "8ef40fa1-774d-42e5-8fd0-c79c5f623480"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Questions</th>\n",
              "      <th>Context</th>\n",
              "      <th>start_idx</th>\n",
              "      <th>end_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Will the pre-class session be recorded?</td>\n",
              "      <td>The course schedule may include readings in th...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the deadline for quiz submission?</td>\n",
              "      <td>The exercises that you worked on during the ma...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the deadline for exercise submission?</td>\n",
              "      <td>The exercises that you worked on during the ma...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How many hours do I need to complete this course?</td>\n",
              "      <td>Our courses need a time commitment of about 15...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Who will grade the exercise?</td>\n",
              "      <td>We conduct both group and individual evaluatio...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Questions  ... end_idx\n",
              "0            Will the pre-class session be recorded?  ...       2\n",
              "1          What is the deadline for quiz submission?  ...       2\n",
              "2      What is the deadline for exercise submission?  ...       2\n",
              "3  How many hours do I need to complete this course?  ...       2\n",
              "4                       Who will grade the exercise?  ...       2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBoJJ_XEitwB"
      },
      "source": [
        "val_questions = df_test.Questions.tolist()\n",
        "val_questions = clean_data(val_questions)\n",
        "\n",
        "# The possible contexts\n",
        "contexts = df_con.Context.tolist()\n",
        "contexts = clean_data(contexts)\n",
        "\n",
        "# Dummy answers and start_idx for ease of pre-processing\n",
        "val_answers = ['No Provided Answer']*len(val_questions)\n",
        "\n",
        "val_start_idx = df_test.start_idx.tolist()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPmu_Cx3ilQY"
      },
      "source": [
        "# The pretrained cross encoder model is loaded, with maximum length set at 512\n",
        "model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2', max_length=512)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wclJ1-LbilQZ"
      },
      "source": [
        "# The score is found for each question against each context vector, the highest score context vector is chosen then for that question.\n",
        "val_contexts = []\n",
        "for question in val_questions:\n",
        "  que_cont = [(question, text) for text in contexts]\n",
        "  scores = model.predict(que_cont)\n",
        "  ind = np.argmax(scores)\n",
        "  val_contexts.append(contexts[ind])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zV1C99rdzk0"
      },
      "source": [
        "## Load Tokenizer & Preprocess the data\n",
        "\n",
        "1. Go through the JSON file and store every record as a SquadExample object.\n",
        "2. Go through each SquadExample and create x_train, y_train, x_eval, y_eval.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0tUNNGLpG9s"
      },
      "source": [
        "max_len = 384 # The maximum length is set as 384"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM-ErmI8lzs6"
      },
      "source": [
        "tokenizer = AlbertTokenizerFast.from_pretrained('albert-large-v2')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5p972zSSdzk0",
        "outputId": "bd1fb361-7e70-435d-bf76-a04d172fd078"
      },
      "source": [
        "# SquadExample class is used for making an object for each question in SQuAD\n",
        "class SquadExample:\n",
        "    def __init__(self, question, context, start_char_idx, answer_text):\n",
        "        self.question = question\n",
        "        self.context = context\n",
        "        self.start_char_idx = start_char_idx\n",
        "        self.answer_text = answer_text\n",
        "        self.skip = False\n",
        "\n",
        "    def preprocess(self):\n",
        "        context = self.context\n",
        "        question = self.question\n",
        "        answer_text = self.answer_text\n",
        "        start_char_idx = self.start_char_idx\n",
        "\n",
        "        # Clean context, answer and question\n",
        "        context = \" \".join(str(context).split())\n",
        "        question = \" \".join(str(question).split())\n",
        "        answer = \" \".join(str(answer_text).split())\n",
        "\n",
        "        # Find end character index of answer in context\n",
        "        end_char_idx = start_char_idx + len(answer)\n",
        "        if end_char_idx >= len(context):\n",
        "            self.skip = True\n",
        "            return\n",
        "\n",
        "        # Mark the character indexes in context that are in answer\n",
        "        is_char_in_ans = [0] * len(context)\n",
        "        for idx in range(start_char_idx, end_char_idx):\n",
        "            is_char_in_ans[idx] = 1\n",
        "\n",
        "        # Tokenize context\n",
        "        tokenized_context = tokenizer(context, return_offsets_mapping=True)\n",
        "\n",
        "        # Find tokens that were created from answer characters\n",
        "        ans_token_idx = []\n",
        "        for idx, start_end in enumerate(tokenized_context['offset_mapping']):\n",
        "            start = start_end[0]\n",
        "            end = start_end[1]\n",
        "            if sum(is_char_in_ans[start:end]) > 0:\n",
        "                ans_token_idx.append(idx)\n",
        "\n",
        "        if len(ans_token_idx) == 0:\n",
        "            self.skip = True\n",
        "            return\n",
        "\n",
        "        # Find start and end token index for tokens from answer\n",
        "        start_token_idx = ans_token_idx[0]\n",
        "        end_token_idx = ans_token_idx[-1]\n",
        "\n",
        "        # Tokenize question\n",
        "        tokenized_question = tokenizer(question, return_offsets_mapping=True)\n",
        "\n",
        "        # Create inputs\n",
        "        input_ids = tokenized_context['input_ids'] + tokenized_question['input_ids'][1:]\n",
        "        token_type_ids = [0] * len(tokenized_context['input_ids']) + [1] * len(\n",
        "            tokenized_question['input_ids'][1:]\n",
        "        )\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "\n",
        "        # Pad and create attention masks.\n",
        "        # Skip if truncation is needed\n",
        "        padding_length = max_len - len(input_ids)\n",
        "        if padding_length > 0:  # pad\n",
        "            input_ids = input_ids + ([0] * padding_length)\n",
        "            attention_mask = attention_mask + ([0] * padding_length)\n",
        "            token_type_ids = token_type_ids + ([0] * padding_length)\n",
        "        elif padding_length < 0:  # skip\n",
        "            self.skip = True\n",
        "            return\n",
        "\n",
        "        self.input_ids = input_ids\n",
        "        self.token_type_ids = token_type_ids\n",
        "        self.attention_mask = attention_mask\n",
        "        self.start_token_idx = start_token_idx\n",
        "        self.end_token_idx = end_token_idx\n",
        "        self.context_token_to_char = tokenized_context['offset_mapping']\n",
        "\n",
        "\n",
        "def create_squad_examples(clean_questions, clean_context, clean_answers, start_indexes):\n",
        "    squad_examples = []\n",
        "   \n",
        "    for ques, cont, ans, idx in zip(clean_questions, clean_context, clean_answers, start_indexes):\n",
        "      question = ques\n",
        "      context = cont\n",
        "      answer_text = ans\n",
        "      start_char_idx = idx\n",
        "      squad_eg = SquadExample(\n",
        "          question, context, start_char_idx, answer_text\n",
        "      )\n",
        "      squad_eg.preprocess()\n",
        "      squad_examples.append(squad_eg)\n",
        "    return squad_examples\n",
        "\n",
        "\n",
        "def create_inputs_targets(squad_examples):\n",
        "    dataset_dict = {\n",
        "        \"input_ids\": [],\n",
        "        \"token_type_ids\": [],\n",
        "        \"attention_mask\": [],\n",
        "        \"start_token_idx\": [],\n",
        "        \"end_token_idx\": [],\n",
        "    }\n",
        "    for item in squad_examples:\n",
        "        if item.skip == False:\n",
        "            for key in dataset_dict:\n",
        "                dataset_dict[key].append(getattr(item, key))\n",
        "    for key in dataset_dict:\n",
        "        dataset_dict[key] = np.array(dataset_dict[key])\n",
        "\n",
        "    x = [\n",
        "        dataset_dict[\"input_ids\"],\n",
        "        dataset_dict[\"token_type_ids\"],\n",
        "        dataset_dict[\"attention_mask\"],\n",
        "    ]\n",
        "    y = [dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"]]\n",
        "    return x, y\n",
        "\n",
        "\n",
        "train_squad_examples = create_squad_examples(train_questions, train_contexts, train_answers, train_start_indexes)\n",
        "x_train, y_train = create_inputs_targets(train_squad_examples)\n",
        "print(f\"{len(train_squad_examples)} training points created.\")\n",
        "\n",
        "eval_squad_examples = create_squad_examples(val_questions, val_contexts, val_answers, val_start_idx)\n",
        "x_eval, y_eval = create_inputs_targets(eval_squad_examples)\n",
        "print(f\"{len(eval_squad_examples)} evaluation points created.\")\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33 training points created.\n",
            "24 evaluation points created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR5Xw4Icdzk2"
      },
      "source": [
        "## **Model Maker** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7JC1A5Zdzk2"
      },
      "source": [
        "Create the Question-Answering Model using ALBERT and Functional API\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UbpAe83dzk3"
      },
      "source": [
        "\n",
        "def create_model():\n",
        "    ## Pretrained ALBERT encoder\n",
        "    encoder = TFAlbertModel.from_pretrained(\"albert-large-v2\")\n",
        "\n",
        "    ## QA Model\n",
        "    input_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    token_type_ids = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    attention_mask = layers.Input(shape=(max_len,), dtype=tf.int32)\n",
        "    # Getting the Contextual EMbeddings from ALBERT\n",
        "    embedding = encoder(\n",
        "        input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask\n",
        "    )[0]\n",
        "    # Initializing the embedding of ALBERT from the fine-tuned weights of SQuAD\n",
        "    embedding_model = keras.Model(\n",
        "        inputs=[input_ids, token_type_ids, attention_mask],\n",
        "        outputs=embedding,\n",
        "    )\n",
        "\n",
        "    embedding_model.load_weights('/content/drive/MyDrive/univai/Project/squad_model.h5')\n",
        "\n",
        "    # The probability for identifying the start index of the attention span\n",
        "    start_logits = layers.Dense(1, name=\"start_logit\", use_bias=False)(embedding)\n",
        "    start_logits = layers.Flatten()(start_logits)\n",
        "\n",
        "    # The probability for identifying the end index of the attention span\n",
        "    end_logits = layers.Dense(1, name=\"end_logit\", use_bias=False)(embedding)\n",
        "    end_logits = layers.Flatten()(end_logits)\n",
        "\n",
        "    # Softmax is applied for getting the probabilities\n",
        "    start_probs = layers.Activation(keras.activations.softmax)(start_logits)\n",
        "    end_probs = layers.Activation(keras.activations.softmax)(end_logits)\n",
        "\n",
        "    model = keras.Model(\n",
        "        inputs=[input_ids, token_type_ids, attention_mask],\n",
        "        outputs=[start_probs, end_probs],\n",
        "    )\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "    optimizer = keras.optimizers.Adam(lr=5e-5)\n",
        "    model.compile(optimizer=optimizer, loss=[loss, loss], metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(name='accuracy')])\n",
        "    # model.load_weights('/content/drive/MyDrive/univai/Project/squad_whole_model.h5')\n",
        "    return model, embedding_model\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ljyu4XaAdzk3"
      },
      "source": [
        "We advise this notebook to be run on Google Colab TPU runtime.\n",
        "With Colab TPUs, each epoch will take 1 second.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDQxkj82dzk3",
        "outputId": "d2fb1a4d-396b-43de-a9c7-23d2dde69269"
      },
      "source": [
        "use_tpu = True\n",
        "if use_tpu:\n",
        "    # Create distribution strategy\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "    # Create model\n",
        "    with strategy.scope():\n",
        "        model, embedding_model = create_model()\n",
        "else:\n",
        "    model, embedding_model = create_model()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.78.167.202:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.78.167.202:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "Some layers from the model checkpoint at albert-large-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
            "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-large-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f282e248e50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f282e248e50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f282e248e50>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f2834e22dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f2834e22dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7f2834e22dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL6MAgdvdzk4",
        "outputId": "39a2b538-fc17-4b45-a162-7f90aacd1e27"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_albert_model (TFAlbertModel) TFBaseModelOutputWit 17683968    input_1[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "start_logit (Dense)             (None, 384, 1)       1024        tf_albert_model[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "end_logit (Dense)               (None, 384, 1)       1024        tf_albert_model[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 384)          0           start_logit[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 384)          0           end_logit[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 384)          0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 384)          0           flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 17,686,016\n",
            "Trainable params: 17,686,016\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpgIxmw-dzk4"
      },
      "source": [
        "# For fine-tuning the ALBERT model on the small UNIV-AI dataset we'll be initializing the weights for the ALBERT embeddings from the \n",
        "#above trained SQuAD model and freeze them, only the dense layer for getting the probabilities of start and end token is trained.\n",
        "albert_layer = model.get_layer('tf_albert_model')\n",
        "albert_layer.trainable = False"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCTVqFGfdzk5",
        "outputId": "64024c2f-bdb4-4019-de07-3ea238bcb94d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 384)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_albert_model (TFAlbertModel) TFBaseModelOutputWit 17683968    input_1[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "start_logit (Dense)             (None, 384, 1)       1024        tf_albert_model[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "end_logit (Dense)               (None, 384, 1)       1024        tf_albert_model[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 384)          0           start_logit[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 384)          0           end_logit[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 384)          0           flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 384)          0           flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 17,686,016\n",
            "Trainable params: 2,048\n",
            "Non-trainable params: 17,683,968\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8tx3G32dzk5"
      },
      "source": [
        "## Create evaluation Callback\n",
        "\n",
        "This callback will will save the a CSV file containing the question and it's predicted answer for each epoch.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvElbJrsdzk5"
      },
      "source": [
        "from collections import Counter\n",
        "def normalize_text(text):\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuations\n",
        "    exclude = set(string.punctuation)\n",
        "    text = \"\".join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    # Remove articles\n",
        "    regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "    text = re.sub(regex, \" \", text)\n",
        "\n",
        "    # Remove extra white space\n",
        "    text = \" \".join(text.split())\n",
        "    return text\n",
        "\n",
        "\n",
        "class Predicted_Ans(keras.callbacks.Callback):\n",
        "\n",
        "    def __init__(self, x_eval, y_eval):\n",
        "        self.x_eval = x_eval\n",
        "        self.y_eval = y_eval\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        pred_start, pred_end = self.model.predict(self.x_eval)\n",
        "        count = 0\n",
        "        predicted_answers = []\n",
        "        questions = []\n",
        "        eval_examples_no_skip = [_ for _ in eval_squad_examples if _.skip == False]\n",
        "        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
        "            squad_eg = eval_examples_no_skip[idx]\n",
        "            offsets = squad_eg.context_token_to_char\n",
        "            start = np.argmax(start)\n",
        "            end = np.argmax(end)\n",
        "            if start >= len(offsets):\n",
        "                continue\n",
        "            pred_char_start = offsets[start][0]\n",
        "            if end < len(offsets):\n",
        "                pred_char_end = offsets[end][1]\n",
        "                pred_ans = squad_eg.context[pred_char_start:pred_char_end]\n",
        "            else:\n",
        "                pred_ans = squad_eg.context[pred_char_start:]\n",
        "\n",
        "            normalized_pred_ans = normalize_text(pred_ans)\n",
        "\n",
        "            questions.append(normalize_text(squad_eg.question))\n",
        "            predicted_answers.append(normalized_pred_ans)\n",
        "\n",
        "        df_dict = {'Question' : questions, 'Answer' : predicted_answers}\n",
        "        df = pd.DataFrame(df_dict, columns=['Question','Answer'])\n",
        "        if epoch%1 == 0:\n",
        "          df.to_csv('/content/drive/MyDrive/univai/Project/Univ_pred/auto_predicted_albert' + str(epoch) + '.csv', index=False)\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce19SGeodzk6"
      },
      "source": [
        "## Train and Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0Hv59NDdzk6",
        "outputId": "ded7df91-730a-4f11-dc56-ae0ec9a03019"
      },
      "source": [
        "predicted_answers = Predicted_Ans(x_eval, y_eval)\n",
        "num_epochs = 10\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=10,  # For demonstration, 3 epochs are recommended\n",
        "    verbose=1,\n",
        "    batch_size=33,\n",
        "    callbacks=[predicted_answers],\n",
        ")\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None,) dtype=int64>, <tf.Tensor 'cond_8/Identity_4:0' shape=(None,) dtype=int64>]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss.\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None,) dtype=int64>, <tf.Tensor 'cond_8/Identity_4:0' shape=(None,) dtype=int64>]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_albert_model/albert/pooler/kernel:0', 'tf_albert_model/albert/pooler/bias:0'] when minimizing the loss.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 76s 76s/step - loss: 12.0311 - activation_loss: 5.6953 - activation_1_loss: 6.3358 - activation_accuracy: 0.1429 - activation_1_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 384) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 384) dtype=int64>]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/10\n",
            "1/1 [==============================] - 0s 257ms/step - loss: 8.2067 - activation_loss: 3.5914 - activation_1_loss: 4.6153 - activation_accuracy: 0.6786 - activation_1_accuracy: 0.2857\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 6.4834 - activation_loss: 2.6026 - activation_1_loss: 3.8808 - activation_accuracy: 0.9286 - activation_1_accuracy: 0.4286\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 4.9896 - activation_loss: 1.5556 - activation_1_loss: 3.4341 - activation_accuracy: 0.9643 - activation_1_accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 3.8897 - activation_loss: 0.8349 - activation_1_loss: 3.0548 - activation_accuracy: 1.0000 - activation_1_accuracy: 0.5357\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 249ms/step - loss: 3.2078 - activation_loss: 0.5565 - activation_1_loss: 2.6513 - activation_accuracy: 1.0000 - activation_1_accuracy: 0.6786\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 2.4873 - activation_loss: 0.4427 - activation_1_loss: 2.0446 - activation_accuracy: 1.0000 - activation_1_accuracy: 0.8214\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 253ms/step - loss: 1.8030 - activation_loss: 0.2496 - activation_1_loss: 1.5534 - activation_accuracy: 1.0000 - activation_1_accuracy: 0.9286\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 0s 252ms/step - loss: 1.2696 - activation_loss: 0.0996 - activation_1_loss: 1.1699 - activation_accuracy: 1.0000 - activation_1_accuracy: 0.9643\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 0.8956 - activation_loss: 0.0507 - activation_1_loss: 0.8449 - activation_accuracy: 1.0000 - activation_1_accuracy: 0.9643\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f25561b5f10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "g5H20vPvmWta",
        "outputId": "61d00f80-c566-44eb-af1c-084f99b25853"
      },
      "source": [
        "df_univ_qa = pd.read_csv('/content/drive/MyDrive/univai/Project/Univ_pred/auto_predicted_albert9.csv')\n",
        "df_univ_qa"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>will preclass session be recorded</td>\n",
              "      <td>course schedule may include readings in course...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what is deadline for quiz submission</td>\n",
              "      <td>5 pm on day of following lecture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what is deadline for exercise submission</td>\n",
              "      <td>5 pm on day of following lecture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>how many hours do i need to complete this course</td>\n",
              "      <td>our courses need time commitment of about 15 h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>who will grade exercise</td>\n",
              "      <td>exercises are autograded once you click submit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>why is autograder failing me</td>\n",
              "      <td>autograder does not accept alternative solutions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>do i do exercises individually</td>\n",
              "      <td>students submit exercises individually but you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>is lab compulsory</td>\n",
              "      <td>labs are not compulsory and will mostly review...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>will sessions be recorded</td>\n",
              "      <td>our lectures and labs are carried out via</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>can i have access to recorded videos</td>\n",
              "      <td>our lectures and labs are carried out via zoom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>where are recordings</td>\n",
              "      <td>our lectures and labs are carried out via zoom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>where can i ask questions regarding reading ma...</td>\n",
              "      <td>all material is available on edstem were using...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>where to find course material</td>\n",
              "      <td>all material is available on edstem</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>do we have homework</td>\n",
              "      <td>each session has exercise and there is homewor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>where can i find homework</td>\n",
              "      <td>please fill in google sheet with your name and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>where to submit homework</td>\n",
              "      <td>you and your partner are required to submit ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>where do i find homework</td>\n",
              "      <td>please fill in google sheet with your name and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>where do i submit my homework assignment</td>\n",
              "      <td>you and your partner are required to submit ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>will professor take office hours</td>\n",
              "      <td>your tas will take office hours</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>what is oh zoom link</td>\n",
              "      <td>please check course information slide for zoom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>what will we do in projects</td>\n",
              "      <td>significant part of this course is group proje...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>what should be duration of presentation video</td>\n",
              "      <td>5 minute video along</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>do i need to submit project in group</td>\n",
              "      <td>significant part of this course is group project</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>does attendance count to grading</td>\n",
              "      <td>small component of grading is allocated to cla...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Question                                             Answer\n",
              "0                   will preclass session be recorded  course schedule may include readings in course...\n",
              "1                what is deadline for quiz submission                   5 pm on day of following lecture\n",
              "2            what is deadline for exercise submission                   5 pm on day of following lecture\n",
              "3    how many hours do i need to complete this course  our courses need time commitment of about 15 h...\n",
              "4                             who will grade exercise  exercises are autograded once you click submit...\n",
              "5                        why is autograder failing me   autograder does not accept alternative solutions\n",
              "6                      do i do exercises individually  students submit exercises individually but you...\n",
              "7                                   is lab compulsory  labs are not compulsory and will mostly review...\n",
              "8                           will sessions be recorded          our lectures and labs are carried out via\n",
              "9                can i have access to recorded videos  our lectures and labs are carried out via zoom...\n",
              "10                               where are recordings  our lectures and labs are carried out via zoom...\n",
              "11  where can i ask questions regarding reading ma...  all material is available on edstem were using...\n",
              "12                      where to find course material                all material is available on edstem\n",
              "13                                do we have homework  each session has exercise and there is homewor...\n",
              "14                          where can i find homework  please fill in google sheet with your name and...\n",
              "15                           where to submit homework  you and your partner are required to submit ho...\n",
              "16                           where do i find homework  please fill in google sheet with your name and...\n",
              "17           where do i submit my homework assignment  you and your partner are required to submit ho...\n",
              "18                   will professor take office hours                    your tas will take office hours\n",
              "19                               what is oh zoom link  please check course information slide for zoom...\n",
              "20                        what will we do in projects  significant part of this course is group proje...\n",
              "21      what should be duration of presentation video                               5 minute video along\n",
              "22               do i need to submit project in group   significant part of this course is group project\n",
              "23                   does attendance count to grading  small component of grading is allocated to cla..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krt055gOmXga"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFXrtlnxmXiJ"
      },
      "source": [
        "# masked_texts = []\n",
        "# for text in texts:\n",
        "#   splitt = text.split()\n",
        "#   num_mask = int(0.2*len(splitt))\n",
        "#   rand_ind = np.random.randint(len(splitt), size = num_mask)\n",
        "#   for ind in rand_ind:\n",
        "#     splitt[ind] = '[MASK]'\n",
        "#   masked_texts.append(\" \".join(splitt))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-6hXzmtol51"
      },
      "source": [
        "# T5 (from HuggingFace Transformers) for Text Extraction\n",
        "\n",
        "The abstract from the paper is the following:\n",
        "\n",
        "Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts every language problem into a text-to-text format. Our systematic study compares pretraining objectives, architectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new “Colossal Clean Crawled Corpus”, we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our dataset, pre-trained models, and code.\n",
        "\n",
        "So basically T5 is an encoder-decoder model pre-trained on a multi-task mixture of unsupervised and supervised tasks and the best pretraining methods were used after various trials. In T5 each task is converted into a text-to-text format. T5 works well on a variety of tasks out-of-the-box by prepending a different prefix to the input corresponding to each task, e.g., for translation: translate English to German: …, for summarization: summarize: ….\n",
        "\n",
        "###**Our main reason for trying out T5 is it's generative capabilities, which makes it useful even when the context is not provided i.e. closed book QA scenario. But for that we require a decent amount of data first for finetuning, else the generative model won't be able to perform good. Right now we're just putting out the possibility of using it in future and not expecting good results on the current provided dataset.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5g4juGfgol54"
      },
      "source": [
        "## Introduction to Datset & Training Method\n",
        "\n",
        "This demonstration uses SQuAD (Stanford Question-Answering Dataset).\n",
        "In SQuAD, an input consists of a question, and a paragraph for context.\n",
        "The goal is to find the span of text in the paragraph that answers the question.\n",
        "We evaluate our performance on this data with the \"Exact Match\" metric,\n",
        "which measures the percentage of predictions that exactly match any one of the\n",
        "ground-truth answers.\n",
        "\n",
        "We fine-tune a T5 model to perform this task as follows:\n",
        "\n",
        "1. Feed the context and the question as inputs to T5 encoder and the answer  the right shifted answer to the decoder input.\n",
        "2. The embeddings from the decoder are taken and sent through a dense softmax layer, with units equal to the vocab of T5 tokenizer.\n",
        "\n",
        "\n",
        "**References:**\n",
        "\n",
        "- [T5](https://arxiv.org/abs/1910.10683)\n",
        "- [SQuAD](https://arxiv.org/abs/1606.05250)\n",
        "- [BERT CODE](https://keras.io/examples/nlp/text_extraction_with_bert/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg35yxL_ol55"
      },
      "source": [
        "# **Fine Tuning on Squad**\n",
        "\n",
        "1. The results on SQuAD from the T5 model were good, we could not find the exactmatch score and f1 score as we are using our own custom made generate function, which is not paralelized. So, it was taking alot of hours for  evaluating 10000 questions test data. Nevertheless, we have shown the output of the first 50 questions generated by the T5 model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDJADckbol57"
      },
      "source": [
        "max_len = 384\n",
        "configuration = T5Config()  # default parameters and configuration for BERT"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6StZQG-ol58"
      },
      "source": [
        "## Load the data & Tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZyRe6mVol58",
        "outputId": "7631c687-dd95-4cc3-cf2a-cec84111a8a5"
      },
      "source": [
        "# load train and validation split of squad\n",
        "train_dataset = load_dataset('squad', split='train')\n",
        "valid_dataset = load_dataset('squad', split='validation')\n",
        "\n",
        "# train_dataset.features"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/4fffa6cf76083860f85fa83486ec3028e7e32c342c218ff2a620fc6b2868483a)\n",
            "Reusing dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/4fffa6cf76083860f85fa83486ec3028e7e32c342c218ff2a620fc6b2868483a)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAGBZVvRol58"
      },
      "source": [
        "tokenizer = T5TokenizerFast.from_pretrained('t5-base')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqv17U4LaewH"
      },
      "source": [
        "encoder_max_len = 250\n",
        "decoder_max_len = 25 \n",
        "global_counter = 0"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EiP32k5ol5-"
      },
      "source": [
        "def encode(example, encoder_max_len= 250, decoder_max_len = 25, bool_obj = True):\n",
        "    if global_counter == 1:\n",
        "      bool_obj = False\n",
        "    # print(bool_obj)\n",
        "    context = example['context']\n",
        "    question = example['question']\n",
        "    answer = example['answers']['text']\n",
        "  \n",
        "    question_plus = f\"answer_me: {str(question)}\"\n",
        "    context_plus = f\"context: {str(context)}\"\n",
        "    \n",
        "    answer_plus = ', '.join([i for i in list(answer)])\n",
        "    answer_plus = f\"<pad> {answer_plus}\"\n",
        "    \n",
        "    encoder_inputs = tokenizer(question_plus, context_plus, truncation=bool_obj, max_length=encoder_max_len, pad_to_max_length=bool_obj)\n",
        "    \n",
        "    decoder_inputs = tokenizer(answer_plus, truncation=bool_obj, max_length=decoder_max_len, pad_to_max_length=bool_obj)\n",
        "    \n",
        "    input_ids = encoder_inputs['input_ids']\n",
        "    input_attention = encoder_inputs['attention_mask']\n",
        "    target_ids = decoder_inputs['input_ids']\n",
        "    target_attention = decoder_inputs['attention_mask']\n",
        "    \n",
        "    outputs = {'input_ids':input_ids, 'attention_mask': input_attention, \n",
        "               'decoder_input_ids':target_ids, 'decoder_attention_mask':target_attention}\n",
        "    return outputs"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184,
          "referenced_widgets": [
            "f1a80501a33549888c1482643c9aa73f",
            "ddcf0f1107494f30ae9d6d47e13ea533",
            "062ff324979545e6b8833d4d156826a6",
            "fa0c20525ce540648e3ea1f7ef204f80",
            "f76fd7de38a1439ba16ca61ddeaadbca",
            "1a051c563581488cb1830ce59ce48610",
            "f0688d7be73d4bf9a96cff1e147d0712",
            "c0ed805aaa554624aafcba6839f31d2d",
            "531d0c28f3934f7e88ca382a32fa127c",
            "d6e655ca30944d048fe0004f37f5f8a8",
            "d8d8b918763a409faddf993fbb530db8",
            "57ee6f11f0c44802a9d3fe0e81beaf61",
            "27adb0694cc94a96b0f394836648d2e7",
            "2a0fa2e2088c4ead82693d5d75512b76",
            "a3cb12e127064bf0a915e7baf984593c",
            "ff00cc469c79475aa5fa22b65842ce7a"
          ]
        },
        "id": "ZaULvoprqvm7",
        "outputId": "8ca63d4c-2f45-4e09-f512-886cf96815b8"
      },
      "source": [
        "# map function to the dataset example wise \n",
        "train_ds=  train_dataset.map(encode)\n",
        "global_counter = 1\n",
        "valid_ds=  valid_dataset.map(encode)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1a80501a33549888c1482643c9aa73f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=87599.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "531d0c28f3934f7e88ca382a32fa127c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=10570.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkh_jERIs0Ic"
      },
      "source": [
        "x_train = [np.array(train_ds['input_ids']), np.array(train_ds['attention_mask']), np.array(train_ds['decoder_input_ids'])[:, :-1], np.array(train_ds['decoder_attention_mask'])[:, :-1]]\n",
        "y_train = np.array(train_ds['decoder_input_ids'])[:, 1:]\n",
        "\n",
        "x_eval = [valid_ds['input_ids'], valid_ds['attention_mask']]\n",
        "y_eval = valid_ds['decoder_input_ids']"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V28-GrGIY90i"
      },
      "source": [
        "# x_train[2][x_train[2] == 0] = -100"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZkz1Z8eZuqm"
      },
      "source": [
        "# y_train[y_train == 0] = -100"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pY88jSdQol5_"
      },
      "source": [
        "## **Model Maker** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ngwzUbxol5_"
      },
      "source": [
        "Create the Question-Answering Model using T5 and Functional API\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FNMphw-ol5_"
      },
      "source": [
        "\n",
        "def create_model():\n",
        "    ## T5 encoder\n",
        "    encoder = TFT5Model.from_pretrained(\"t5-base\")\n",
        "\n",
        "    ## QA Model\n",
        "    input_ids = layers.Input(shape=(None,), dtype=tf.int32)\n",
        "    decoder_input_ids = layers.Input(shape=(None,), dtype=tf.int32)\n",
        "    attention_mask = layers.Input(shape=(None,), dtype=tf.int32)\n",
        "    decoder_attention_mask = layers.Input(shape=(None,), dtype=tf.int32)\n",
        "    # Getting the Contextual EMbeddings from T5\n",
        "    embedding = encoder(input_ids  = input_ids, decoder_input_ids =decoder_input_ids, attention_mask=attention_mask, decoder_attention_mask = decoder_attention_mask)[0]\n",
        "\n",
        "    embedding_model = keras.Model(\n",
        "        inputs=[input_ids, attention_mask, decoder_input_ids, decoder_attention_mask],\n",
        "        outputs=embedding,\n",
        "    )\n",
        "\n",
        "    # embedding_model.load_weights('/content/drive/MyDrive/univai/Project/T5_emb_model.h5')\n",
        "\n",
        "    # Appling a softmax with dense of units = vocab_size\n",
        "    qa_head = layers.Dense(configuration.vocab_size, name=\"qa_head\", activation = 'softmax')(embedding)\n",
        "\n",
        "    model = keras.Model(\n",
        "        inputs=[input_ids, attention_mask, decoder_input_ids, decoder_attention_mask],\n",
        "        outputs=qa_head)\n",
        "    \n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "    optimizer = keras.optimizers.Adam(lr=5e-5)\n",
        "    model.compile(optimizer=optimizer, loss=[loss, loss], metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(name='accuracy')])\n",
        "    # model.load_weights('/content/drive/MyDrive/univai/Project/T5_model.h5')\n",
        "    return model, embedding_model\n",
        "\n",
        "# def create_model():\n",
        "#   return TFMT5ForConditionalGeneration.from_pretrained(\"google/mt5-small\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af4grLqkol6A"
      },
      "source": [
        "We advise this notebook to be run on Google Colab TPU runtime.\n",
        "With Colab TPUs, each epoch will take 10 minutes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Li0D0AVKol6A",
        "outputId": "652f736e-6589-40f6-aa59-6b96ed615c3d"
      },
      "source": [
        "use_tpu = True\n",
        "if use_tpu:\n",
        "    # Create distribution strategy\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "    # Create model\n",
        "    with strategy.scope():\n",
        "        model, embedding_model = create_model()\n",
        "else:\n",
        "    model, embedding_model = create_model()\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.109.240.202:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.109.240.202:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "All model checkpoint layers were used when initializing TFT5Model.\n",
            "\n",
            "All the layers of TFT5Model were initialized from the model checkpoint at t5-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5Model for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7ff142e8af30>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7ff142e8af30>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7ff142e8af30>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7ff159a84dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7ff159a84dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7ff159a84dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_t5model (TFT5Model)          TFSeq2SeqModelOutput 222903552   input_1[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "qa_head (Dense)                 (None, None, 32128)  24706432    tf_t5model[0][1]                 \n",
            "==================================================================================================\n",
            "Total params: 247,609,984\n",
            "Trainable params: 247,609,984\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNa6wnl4oIXV"
      },
      "source": [
        "# for layer in encoder.layers:\n",
        "#   for weight in layer.weights:\n",
        "#     print(weight.name)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNVgHGZKol6A"
      },
      "source": [
        "## Create Evaluation Function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-nfrQI0cicF"
      },
      "source": [
        "MAX_LENGTH = 16"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ86EN0nw7u5"
      },
      "source": [
        "########################################\n",
        "# search strategy: temperature (re-shape)\n",
        "########################################\n",
        "def temperature(logits, temperature):\n",
        "        probs = np.exp(logits / temperature) / np.sum(np.exp(logits / temperature))\n",
        "        return probs\n",
        "\n",
        "\n",
        "########################################\n",
        "# search strategy: nucleus (truncate)\n",
        "########################################\n",
        "def nucleus(probs, p):\n",
        "    \n",
        "    probs /= sum(probs)\n",
        "    sorted_probs = np.sort(probs)[::-1]\n",
        "    sorted_index = np.argsort(probs)[::-1]\n",
        "    cusum_sorted_probs = np.cumsum(sorted_probs)\n",
        "    after_threshold = cusum_sorted_probs > p\n",
        "    if sum(after_threshold) > 0:\n",
        "        last_index = np.where(after_threshold)[0][-1]\n",
        "        candi_index = sorted_index[:last_index]\n",
        "    else:\n",
        "        candi_index = sorted_index[:3] # just assign a value\n",
        "    candi_probs = [probs[i] for i in candi_index]\n",
        "    candi_probs /= sum(candi_probs)\n",
        "    word = np.random.choice(candi_index, size=1, p=candi_probs)[0]\n",
        "  \n",
        "    return word"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0mcFIp-Z63N"
      },
      "source": [
        "def evaluate(sentence):\n",
        "  input_ids = np.array(sentence[0]).reshape(1,-1)\n",
        "  attention_mask = np.array(sentence[1]).reshape(1,-1)\n",
        "  decoder_data = tokenizer(\"<pad>\")\n",
        "  decoder_data = {'input_ids' : decoder_data['input_ids'][:-1], 'attention_mask' : decoder_data['attention_mask'][:-1]}\n",
        "  decoder_input_ids = np.array(decoder_data['input_ids']).reshape(1,-1)\n",
        "  decoder_attention_mask = np.array(decoder_data['attention_mask']).reshape(1,-1)\n",
        "\n",
        "  for i in range(MAX_LENGTH):\n",
        "    predictions = model.predict([input_ids, attention_mask, decoder_input_ids, decoder_attention_mask])\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[:, -1:, :]#.reshape(-1)\n",
        "    predicted_id = np.argmax(predictions, axis=-1)\n",
        "    # probs = temperature(logits=predictions, temperature=1.0)\n",
        "    # predicted_id = nucleus(probs=probs, p=0.90)\n",
        "    predicted_id = predicted_id[0][0]\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if predicted_id == 1:\n",
        "      break\n",
        "\n",
        "    # concatenated the predicted_id to the output which is given to the decoder as its input.\n",
        "    decoder_input_ids = np.append(decoder_input_ids.reshape(-1), np.array([predicted_id])).reshape(1,-1)\n",
        "    decoder_attention_mask = np.ones((1, decoder_input_ids.shape[1]))\n",
        "    # print(decoder_input_ids)\n",
        "\n",
        "  return decoder_input_ids\n",
        "\n",
        "def predict(sentence):\n",
        "  prediction = evaluate(sentence)\n",
        "  predicted_sentence = tokenizer.decode([i for i in prediction[0] if i < tokenizer.vocab_size])\n",
        "  return predicted_sentence"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3taaDAzvPO8"
      },
      "source": [
        "# evaluate()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLvtJ1aVcSGt"
      },
      "source": [
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "def normalize_answer(s):\n",
        "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "    def remove_articles(text):\n",
        "        return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return ' '.join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return ''.join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "\n",
        "def f1_score(prediction, ground_truth):\n",
        "    prediction_tokens = normalize_answer(prediction).split()\n",
        "    ground_truth_tokens = normalize_answer(ground_truth).split()\n",
        "    common = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0:\n",
        "        return 0\n",
        "    precision = 1.0 * num_same / len(prediction_tokens)\n",
        "    recall = 1.0 * num_same / len(ground_truth_tokens)\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "def exact_match_score(prediction, ground_truth):\n",
        "    return (normalize_answer(prediction) == normalize_answer(ground_truth))\n",
        "\n",
        "def metric_max_over_ground_truths(metric_fn, prediction, ground_truths):\n",
        "    scores_for_ground_truths = []\n",
        "    for ground_truth in ground_truths:\n",
        "        # print(ground_truth)\n",
        "        score = metric_fn(prediction, ground_truth)\n",
        "        scores_for_ground_truths.append(score)\n",
        "    return max(scores_for_ground_truths)\n",
        "\n",
        "def test_metrics(sentences, ground_truths):\n",
        "  f1 = exact_match = total = 0\n",
        "\n",
        "  for i, ground_truth in tqdm(enumerate(ground_truths)):\n",
        "    if i > 50:\n",
        "      break\n",
        "    sentence = [sentences[0][i], sentences[1][i]]\n",
        "    total += 1\n",
        "    prediction = predict(sentence)\n",
        "    gt = tokenizer.decode([i for i in ground_truth if i != 1])\n",
        "    gt = gt.split(',')\n",
        "    temp = gt[0].split()\n",
        "    gt[0] = temp[0]\n",
        "    gt.insert(1, ' ' + \" \".join(temp[1:]))\n",
        "    gt = [gt[0] + gt[i] for i in range(1,len(gt))]\n",
        "    exact_match += metric_max_over_ground_truths(\n",
        "                    exact_match_score, prediction, gt)\n",
        "    f1 += metric_max_over_ground_truths(\n",
        "          f1_score, prediction, gt)\n",
        "    print('\\nReal : ',gt)\n",
        "    print('Pred : ', prediction)\n",
        "\n",
        "  exact_match = 100.0 * exact_match / total\n",
        "  f1 = 100.0 * f1 / total\n",
        "\n",
        "  return {'exact_match': exact_match, 'f1': f1}"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGPQSnuuEQvE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ec3376f0-fb84-4131-8cb7-37b5da0b9e2b"
      },
      "source": [
        "tokenizer.decode([i for i in y_eval[0] if i != 1])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<pad> Denver Broncos, Denver Broncos, Denver Broncos'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzoSoVy3ol6E"
      },
      "source": [
        "## Train and Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgSdgsIPol6E",
        "outputId": "f644040f-da43-41fb-f865-2da5247c45e4"
      },
      "source": [
        "# exact_match_callback = ExactMatch(x_eval, y_eval)\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=3,  # For demonstration, 3 epochs are recommended\n",
        "    verbose=1,\n",
        "    batch_size=16,\n",
        "    validation_split = 0.1\n",
        "    # validation_data = (x_eval, y_eval),\n",
        "    # callbacks=[exact_match_callback],\n",
        ")\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 250) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 250) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 25) dtype=int64>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None, 25) dtype=int64>, <tf.Tensor 'cond_8/Identity_4:0' shape=(None, 25) dtype=int64>]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 250) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 250) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 25) dtype=int64>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None, 25) dtype=int64>, <tf.Tensor 'cond_8/Identity_4:0' shape=(None, 25) dtype=int64>]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4928/4928 [==============================] - ETA: 0s - loss: 1.8287 - accuracy: 0.8318"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:TPU has inputs with dynamic shapes: [<tf.Tensor 'Const:0' shape=() dtype=int32>, <tf.Tensor 'cond_8/Identity:0' shape=(None, 250) dtype=int64>, <tf.Tensor 'cond_8/Identity_1:0' shape=(None, 250) dtype=int64>, <tf.Tensor 'cond_8/Identity_2:0' shape=(None, 25) dtype=int64>, <tf.Tensor 'cond_8/Identity_3:0' shape=(None, 25) dtype=int64>, <tf.Tensor 'cond_8/Identity_4:0' shape=(None, 25) dtype=int64>]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "4928/4928 [==============================] - 802s 135ms/step - loss: 1.8287 - accuracy: 0.8318 - val_loss: 1.2531 - val_accuracy: 0.8589\n",
            "Epoch 2/3\n",
            "4928/4928 [==============================] - 641s 130ms/step - loss: 1.0588 - accuracy: 0.8817 - val_loss: 0.7637 - val_accuracy: 0.9192\n",
            "Epoch 3/3\n",
            "4928/4928 [==============================] - 641s 130ms/step - loss: 0.6081 - accuracy: 0.9439 - val_loss: 0.4095 - val_accuracy: 0.9642\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fee57300c10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yjov3IcJkjnp"
      },
      "source": [
        "# embedding_model.save_weights('/content/drive/MyDrive/univai/Project/T5_emb_model.h5')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfPF3ivr0wgE"
      },
      "source": [
        "# model.save_weights('/content/drive/MyDrive/univai/Project/T5_model.h5')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAuWjy6TOWpw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4febb93-52d8-497a-c8d1-137cfa6a8267"
      },
      "source": [
        "metrics = test_metrics(x_eval, y_eval)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r1it [00:25, 25.16s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> Denver Broncos', '<pad> Denver Broncos', '<pad> Denver Broncos']\n",
            "Pred :  <pad> Colorado Broncos\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r2it [00:27, 18.32s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> Carolina Panthers', '<pad> Carolina Panthers', '<pad> Carolina Panthers']\n",
            "Pred :  <pad> Colorado Broncos\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r3it [00:47, 18.89s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> Santa Clara', '<pad> California', \"<pad> Levi's Stadium\", \"<pad> Levi's Stadium in the San Francisco Bay Area at Santa\"]\n",
            "Pred :  <pad> San Francisco Bay area at Santa Clara, California\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r4it [00:50, 13.98s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> Denver Broncos', '<pad> Denver Broncos', '<pad> Denver Broncos']\n",
            "Pred :  <pad> Colorado Broncos\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r5it [00:59, 12.44s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> gold', '<pad> gold', '<pad> gold']\n",
            "Pred :  <pad> gold\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r6it [01:00,  8.98s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> \"golden anniversary\"', '<pad> gold-themed', '<pad> \"golden anniversary']\n",
            "Pred :  <pad> gold\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r7it [01:01,  6.80s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> February 7', '<pad> 2016', '<pad> February 7', '<pad> February 7', '<pad> 2016']\n",
            "Pred :  <pad> February 7, 2016\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r8it [01:03,  5.27s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> American Football Conference', '<pad> American Football Conference', '<pad> American Football Conference']\n",
            "Pred :  <pad> American Football Conference\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r9it [01:04,  3.95s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> \"golden anniversary\"', '<pad> gold-themed', '<pad> gold']\n",
            "Pred :  <pad> gold\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r10it [01:05,  3.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> American Football Conference', '<pad> American Football Conference', '<pad> American Football Conference']\n",
            "Pred :  <pad> American Football Conference\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r11it [01:07,  2.80s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> February 7', '<pad> 2016', '<pad> February 7', '<pad> February 7', '<pad> 2016']\n",
            "Pred :  <pad> February 7, 2016\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r12it [01:14,  3.97s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> Denver Broncos', '<pad> Denver Broncos', '<pad> Denver Broncos']\n",
            "Pred :  <pad> The American Football Conference (AFA) Champions Colorado Broncos\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r13it [01:16,  3.54s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  [\"<pad> Levi's Stadium\", \"<pad> Levi's Stadium\", \"<pad> Levi's Stadium in the San Francisco Bay Area at Santa Clar\"]\n",
            "Pred :  <pad> Elisas Stadium\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r14it [01:18,  2.87s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> Santa Clara', '<pad> Santa Clara', '<pad> Santa Clara']\n",
            "Pred :  <pad> San Francisco\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r15it [01:19,  2.53s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> Super Bowl L', '<pad> L', '<pad> Super Bowl L']\n",
            "Pred :  <pad> Super Bowl L\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r16it [01:20,  2.03s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> 2015', '<pad> the 2015 season', '<pad> 2015']\n",
            "Pred :  <pad> 2015\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r17it [01:21,  1.68s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> 2015', '<pad> 2016', '<pad> 2015']\n",
            "Pred :  <pad> 2016\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r18it [01:22,  1.56s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> Santa Clara', '<pad> Santa Clara', '<pad> Santa Clara']\n",
            "Pred :  <pad> San Francisco\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r19it [01:25,  1.90s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  [\"<pad> Levi's Stadium\", \"<pad> Levi's Stadium\", \"<pad> Levi's Stadium\"]\n",
            "Pred :  <pad> Elisas Stadium\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r20it [01:27,  1.87s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> 24–10', '<pad> 24–10', '<pad> 24–10']\n",
            "Pred :  <pad> 24–10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r21it [01:29,  1.81s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> February 7', '<pad> 2016', '<pad> February 7', '<pad> 2016', '<pad> February 7', '<pad> 2016']\n",
            "Pred :  <pad> February 7, 2016\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r22it [01:30,  1.53s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> 2015', '<pad> 2016', '<pad> 2016']\n",
            "Pred :  <pad> 2015\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r23it [01:32,  1.87s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> Denver Broncos', '<pad> Denver Broncos', '<pad> Denver Broncos']\n",
            "Pred :  <pad> Colorado Broncos\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r24it [01:34,  1.83s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> Carolina Panthers', '<pad> Carolina Panthers', '<pad> Carolina Panthers']\n",
            "Pred :  <pad> Carolina Panthers\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r25it [01:41,  3.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> Denver Broncos', '<pad> Denver Broncos', '<pad> Denver Broncos']\n",
            "Pred :  <pad> The American Football Conference (AFA) Champions Colorado Broncos\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r26it [01:42,  2.57s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> 2015', '<pad> the 2015 season', '<pad> 2015']\n",
            "Pred :  <pad> 2015\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r27it [01:48,  3.84s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> Denver Broncos', '<pad> Denver Broncos', '<pad> Denver Broncos']\n",
            "Pred :  <pad> The American Football Conference (AFA) Champions Colorado Broncos\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r28it [01:53,  4.15s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> Santa Clara', '<pad> California.', \"<pad> Levi's Stadium\", \"<pad> Levi's Stadium\"]\n",
            "Pred :  <pad> San Francisco Bay area at Santa Clara, California\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r29it [01:55,  3.42s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> Super Bowl', '<pad> Super Bowl', '<pad> Super Bowl']\n",
            "Pred :  <pad> Super Bowl 50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r30it [01:58,  3.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> Denver Broncos', '<pad> Denver Broncos', '<pad> Denver Broncos']\n",
            "Pred :  <pad> Colorado Broncos\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r31it [01:59,  2.62s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> Cam Newton', '<pad> Cam Newton', '<pad> Cam Newton']\n",
            "Pred :  <pad> Cam Newton\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r32it [02:00,  2.09s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> 8', '<pad> eight', '<pad> eight']\n",
            "Pred :  <pad> eight\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r33it [02:01,  1.71s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> 1995', '<pad> 1995', '<pad> 1995']\n",
            "Pred :  <pad> 1995\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r34it [02:02,  1.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> Arizona Cardinals', '<pad> the Arizona Cardinals', '<pad> Arizona Cardinals']\n",
            "Pred :  <pad> Arizona Cardinals\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r35it [02:04,  1.82s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> New England Patriots', '<pad> the New England Patriots', '<pad> New England Patriots']\n",
            "Pred :  <pad> New England Pats\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r36it [02:06,  1.78s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> Arizona Cardinals', '<pad> the Arizona Cardinals', '<pad> Arizona Cardinals']\n",
            "Pred :  <pad> Arizona Cardinals\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r37it [02:08,  1.88s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> New England Patriots', '<pad> the New England Patriots', '<pad> New England Patriots']\n",
            "Pred :  <pad> New England Pats\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r38it [02:10,  1.94s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> New England Patriots', '<pad> the New England Patriots', '<pad> New England Patriots']\n",
            "Pred :  <pad> New England Pats\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r39it [02:11,  1.62s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> four', '<pad> four', '<pad> four']\n",
            "Pred :  <pad> four\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r40it [02:12,  1.51s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> Cam Newton', '<pad> Cam Newton', '<pad> Cam Newton']\n",
            "Pred :  <pad> Cam Newton\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r41it [02:14,  1.58s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> 15–1', '<pad> 15–1', '<pad> 15–1']\n",
            "Pred :  <pad> 15–1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r42it [02:15,  1.48s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> Cam Newton', '<pad> Cam Newton', '<pad> Cam Newton']\n",
            "Pred :  <pad> Cam Newton\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r43it [02:17,  1.56s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> 12–4', '<pad> 12–4', '<pad> 12–4']\n",
            "Pred :  <pad> 12–4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r44it [02:18,  1.35s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> 4', '<pad> four', '<pad> four']\n",
            "Pred :  <pad> four\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r45it [02:20,  1.60s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> New England Patriots', '<pad> the New England Patriots', '<pad> New England Patriots']\n",
            "Pred :  <pad> New England Pats\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r46it [02:21,  1.51s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> Cam Newton', '<pad> Cam Newton', '<pad> Cam Newton']\n",
            "Pred :  <pad> Cam Newton\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r47it [02:23,  1.57s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> Arizona Cardinals', '<pad> the Arizona Cardinals', '<pad> Arizona Cardinals']\n",
            "Pred :  <pad> Arizona Cardinals\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r48it [02:24,  1.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> 2', '<pad> second', '<pad> second']\n",
            "Pred :  <pad> 15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r49it [02:26,  1.44s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> New England Patriots', '<pad> the New England Patriots', '<pad> New England Patriots']\n",
            "Pred :  <pad> Arizona Cardinals\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r50it [02:27,  1.39s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> Cam Newton', '<pad> Cam Newton', '<pad> Cam Newton']\n",
            "Pred :  <pad> Cam Newton\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r51it [02:29,  1.48s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Real :  ['<pad> New England Patriots', '<pad> the New England Patriots', '<pad> New England Patriots']\n",
            "Pred :  <pad> Arizona Cardinals\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBL_P7m0q2n6"
      },
      "source": [
        "# **Fine Tuning on Univ AI(With Manual Context)**\n",
        "\n",
        "1. The results on SQuAD from the T5 model were good, but the finetuned weights were not able to perfrom good on the UNIV-AI dataset that's why we have only shown the reults with the manually mapped context for now. The poor results maybe attributed to the small dataset as generative models require more data. The csv file can by accesses by -[LINK](https://drive.google.com/file/d/1-134Y6oE4H2S4HaBBmu8XfW1uM-oTe6W/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMlwEVjJq2n8"
      },
      "source": [
        "configuration = T5Config()  # default parameters and configuration for BERT"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbu_AkEauHp-"
      },
      "source": [
        "## Load the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOG30hVpuHqA"
      },
      "source": [
        "# Your code here\n",
        "def clean_data(data):\n",
        "    message_list = data\n",
        "    for i in range(len(message_list)):\n",
        "        # Lower Case\n",
        "        message = message_list[i].lower()\n",
        "        \n",
        "        message = \" \".join(message.split())\n",
        "\n",
        "        message_list[i] = message\n",
        "\n",
        "    return message_list"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQMTq4_CuHqA"
      },
      "source": [
        "df_con = pd.read_csv('/content/drive/MyDrive/univai/Project/faq_context.csv')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "ekvYnqXzuHqA",
        "outputId": "3416d8ae-75b5-4668-ea0b-4acfbeb12a98"
      },
      "source": [
        "df_con.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Title</th>\n",
              "      <th>Context</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Pre-class</td>\n",
              "      <td>The course schedule may include readings in th...</td>\n",
              "      <td>Are session pre-class quizzes graded?</td>\n",
              "      <td>No. Pre-class quiz is to just check your under...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Deadlines</td>\n",
              "      <td>The exercises that you worked on during the ma...</td>\n",
              "      <td>When is the deadline for the submission of ses...</td>\n",
              "      <td>5 PM on the day of the following lecture.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Deadlines</td>\n",
              "      <td>The exercises that you worked on during the ma...</td>\n",
              "      <td>Will there be any extension allowed for the qu...</td>\n",
              "      <td>Only for exceptional cases.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Amount of work</td>\n",
              "      <td>Our courses need a time commitment of about 15...</td>\n",
              "      <td>How many hours will I need to dedicate to succ...</td>\n",
              "      <td>About 15 hours per week.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Exercise grading</td>\n",
              "      <td>We conduct both group and individual evaluatio...</td>\n",
              "      <td>Who will grade my exercise?</td>\n",
              "      <td>The exercises are auto-graded once you click t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0             Title  ... Unnamed: 2 Unnamed: 3\n",
              "0           0         Pre-class  ...        NaN        NaN\n",
              "1           1         Deadlines  ...        NaN        NaN\n",
              "2           2         Deadlines  ...        NaN        NaN\n",
              "3           3    Amount of work  ...        NaN        NaN\n",
              "4           4  Exercise grading  ...        NaN        NaN\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06lpXz7FuHqB"
      },
      "source": [
        "questions_list = df_con.Question.tolist()\n",
        "train_questions = clean_data(questions_list)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR1Y_b7MuHqB"
      },
      "source": [
        "answer_list = df_con.Answer.tolist()\n",
        "train_answers = clean_data(answer_list)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR3Zmfi7uHqC"
      },
      "source": [
        "context_list = df_con.Context.tolist()\n",
        "train_contexts = clean_data(context_list)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrDDjjlFuHqC"
      },
      "source": [
        "import pandas as pd\n",
        "df_test = pd.read_csv('/content/drive/MyDrive/univai/Project/test_manual.csv')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "IyasvgXguHqC",
        "outputId": "ed856a1f-a4bd-404e-d5b8-9cc197c2d0fa"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Questions</th>\n",
              "      <th>Context</th>\n",
              "      <th>start_idx</th>\n",
              "      <th>end_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Will the pre-class session be recorded?</td>\n",
              "      <td>The course schedule may include readings in th...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the deadline for quiz submission?</td>\n",
              "      <td>The exercises that you worked on during the ma...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the deadline for exercise submission?</td>\n",
              "      <td>The exercises that you worked on during the ma...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How many hours do I need to complete this course?</td>\n",
              "      <td>Our courses need a time commitment of about 15...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Who will grade the exercise?</td>\n",
              "      <td>We conduct both group and individual evaluatio...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Questions  ... end_idx\n",
              "0            Will the pre-class session be recorded?  ...       2\n",
              "1          What is the deadline for quiz submission?  ...       2\n",
              "2      What is the deadline for exercise submission?  ...       2\n",
              "3  How many hours do I need to complete this course?  ...       2\n",
              "4                       Who will grade the exercise?  ...       2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRqWbh1NuHqD"
      },
      "source": [
        "val_questions = df_test.Questions.tolist()\n",
        "val_questions = clean_data(val_questions)\n",
        "\n",
        "val_answers = ['No Provided Answer']*len(val_questions)\n",
        "\n",
        "val_contexts = df_test.Context.tolist()\n",
        "val_contexts = clean_data(val_contexts)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHOwab_iq2n-"
      },
      "source": [
        "## Preprocess the Data & Load Tokenizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XWz6JHAq2n9"
      },
      "source": [
        "tokenizer = T5TokenizerFast.from_pretrained('t5-base')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7B1RB76iq2n_"
      },
      "source": [
        "def preprocess(context, question, answer):\n",
        "    question_plus = f\"answer_me: {str(question)}\"\n",
        "    context_plus = f\"context: {str(context)}\"\n",
        "    \n",
        "    answer_plus = f\"<pad>{str(answer)}\"\n",
        "\n",
        "    return [question_plus, context_plus, answer_plus]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6JsDaMzxos-",
        "outputId": "c33af7f1-1d80-434b-8d40-88a316e0ffac"
      },
      "source": [
        "ind = 0\n",
        "for context, question, answer in tqdm(zip(train_contexts, train_questions, train_answers)):\n",
        "  listt = preprocess(context, question, answer)\n",
        "  train_questions[ind] = listt[0]\n",
        "  train_contexts[ind] = listt[1]\n",
        "  train_answers[ind] = listt[2]\n",
        "  ind += 1"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33it [00:00, 74776.89it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkU7xEno7Y_f"
      },
      "source": [
        "enocder_train_inputs = tokenizer(train_questions, train_contexts, pad_to_max_length=True, padding = True)\n",
        "decoder_train_inputs = tokenizer(train_answers, pad_to_max_length=True, padding = True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwmdRjvc0Lfr",
        "outputId": "bfc4fb0a-28a8-4576-f421-63bacbc3d21f"
      },
      "source": [
        "ind = 0\n",
        "for context, question, answer in tqdm(zip(val_contexts, val_questions, val_answers)):\n",
        "  listt = preprocess(context, question, answer)\n",
        "  val_questions[ind] = listt[0]\n",
        "  val_contexts[ind] = listt[1]\n",
        "  val_answers[ind] = listt[2]\n",
        "  ind += 1"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24it [00:00, 58695.80it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPqwtz-_8HdG"
      },
      "source": [
        "enocder_val_inputs = tokenizer(val_questions, val_contexts)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye22DSODq2n_"
      },
      "source": [
        "x_train = [np.array(enocder_train_inputs['input_ids']), np.array(enocder_train_inputs['attention_mask']), np.array(decoder_train_inputs['input_ids'])[:, :-1], np.array(decoder_train_inputs['input_ids'])[:, :-1]]\n",
        "y_train = np.array(decoder_train_inputs['input_ids'])[:, 1:]\n",
        "\n",
        "x_eval = [enocder_val_inputs['input_ids'], enocder_val_inputs['attention_mask']]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdZj5Ih9q2oB"
      },
      "source": [
        "## **Model Maker** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6h3sBSHq2oB"
      },
      "source": [
        "Create the Question-Answering Model using T5 and Functional API\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De942N9rq2oB"
      },
      "source": [
        "# \n",
        "def create_model():\n",
        "    ## T5 encoder\n",
        "    encoder = TFT5Model.from_pretrained(\"t5-base\")\n",
        "\n",
        "    ## QA Model\n",
        "    input_ids = layers.Input(shape=(None,), dtype=tf.int32)\n",
        "    decoder_input_ids = layers.Input(shape=(None,), dtype=tf.int32)\n",
        "    attention_mask = layers.Input(shape=(None,), dtype=tf.int32)\n",
        "    decoder_attention_mask = layers.Input(shape=(None,), dtype=tf.int32)\n",
        "    embedding = encoder(input_ids  = input_ids, decoder_input_ids =decoder_input_ids, attention_mask=attention_mask, decoder_attention_mask = decoder_attention_mask)[0]\n",
        "\n",
        "    embedding_model = keras.Model(\n",
        "        inputs=[input_ids, attention_mask, decoder_input_ids, decoder_attention_mask],\n",
        "        outputs=embedding,\n",
        "    )\n",
        "\n",
        "    # Loading the weights from the finetuned model on T5\n",
        "    embedding_model.load_weights('/content/drive/MyDrive/univai/Project/T5_emb_model.h5')\n",
        "\n",
        "    qa_head = layers.Dense(configuration.vocab_size, name=\"qa_head\", activation = 'softmax')(embedding)\n",
        "\n",
        "    model = keras.Model(\n",
        "        inputs=[input_ids, attention_mask, decoder_input_ids, decoder_attention_mask],\n",
        "        outputs=qa_head)\n",
        "    \n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "    optimizer = keras.optimizers.Adam(lr=5e-4)\n",
        "    model.compile(optimizer=optimizer, loss=[loss, loss], metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(name='accuracy')])\n",
        "    # model.load_weights('/content/drive/MyDrive/univai/Project/T5_univ_man_model.h5')\n",
        "    return model, embedding_model\n",
        "\n",
        "# def create_model():\n",
        "#   return TFMT5ForConditionalGeneration.from_pretrained(\"google/mt5-small\")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kNkH2IEq2oB"
      },
      "source": [
        "This code should preferably be run on Google Colab TPU runtime.\n",
        "With Colab TPUs, each epoch will take 1 second.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXg1-dG3q2oB",
        "outputId": "b9fd3baa-2484-4111-f00b-fe55401831d2"
      },
      "source": [
        "use_tpu = True\n",
        "if use_tpu:\n",
        "    # Create distribution strategy\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "\n",
        "    # Create model\n",
        "    with strategy.scope():\n",
        "        model, embedding_model = create_model()\n",
        "else:\n",
        "    model, embedding_model = create_model()\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.67.3.2:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.67.3.2:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n",
            "All model checkpoint layers were used when initializing TFT5Model.\n",
            "\n",
            "All the layers of TFT5Model were initialized from the model checkpoint at t5-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5Model for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f39ad9bcf30>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f39ad9bcf30>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f39ad9bcf30>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f39bc5a0dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f39bc5a0dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7f39bc5a0dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6F1SjBY02xI",
        "outputId": "7c64d5b8-ab31-40d9-8029-f79151f27c27"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_t5model (TFT5Model)          TFSeq2SeqModelOutput 222903552   input_1[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "qa_head (Dense)                 (None, None, 32128)  24706432    tf_t5model[0][1]                 \n",
            "==================================================================================================\n",
            "Total params: 247,609,984\n",
            "Trainable params: 247,609,984\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_8E_vtxq2oB"
      },
      "source": [
        "# Freezing the embeeddings layer\n",
        "t5_layer = model.layers[4]\n",
        "t5_layer.trainable = False"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0NM6dS506zt",
        "outputId": "a2725032-72d6-4434-e231-b4996c7ebf4f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_t5model (TFT5Model)          TFSeq2SeqModelOutput 222903552   input_1[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "qa_head (Dense)                 (None, None, 32128)  24706432    tf_t5model[0][1]                 \n",
            "==================================================================================================\n",
            "Total params: 247,609,984\n",
            "Trainable params: 24,706,432\n",
            "Non-trainable params: 222,903,552\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UulRd7Iwq2oC"
      },
      "source": [
        "## Create Evaluation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qwe-lsQsq2oC"
      },
      "source": [
        "MAX_LENGTH = 50"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEkLJdDVq2oC"
      },
      "source": [
        "\n",
        "########################################\n",
        "# search strategy: temperature (re-shape)\n",
        "########################################\n",
        "def temperature(logits, temperature):\n",
        "        probs = np.exp(logits / temperature) / np.sum(np.exp(logits / temperature))\n",
        "        return probs\n",
        "\n",
        "\n",
        "########################################\n",
        "# search strategy: nucleus (truncate)\n",
        "########################################\n",
        "def nucleus(probs, p):\n",
        "    \n",
        "    probs /= sum(probs)\n",
        "    sorted_probs = np.sort(probs)[::-1]\n",
        "    sorted_index = np.argsort(probs)[::-1]\n",
        "    cusum_sorted_probs = np.cumsum(sorted_probs)\n",
        "    after_threshold = cusum_sorted_probs > p\n",
        "    if sum(after_threshold) > 0:\n",
        "        last_index = np.where(after_threshold)[0][-1]\n",
        "        candi_index = sorted_index[:last_index]\n",
        "    else:\n",
        "        candi_index = sorted_index[:3] # just assign a value\n",
        "    candi_probs = [probs[i] for i in candi_index]\n",
        "    candi_probs /= sum(candi_probs)\n",
        "    word = np.random.choice(candi_index, size=1, p=candi_probs)[0]\n",
        "  \n",
        "    return word"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3fwXMJrq2oD"
      },
      "source": [
        "def evaluate(sentence):\n",
        "  input_ids = np.array(sentence[0]).reshape(1,-1)\n",
        "  attention_mask = np.array(sentence[1]).reshape(1,-1)\n",
        "  decoder_data = tokenizer(\"<pad>\")\n",
        "  decoder_data = {'input_ids' : decoder_data['input_ids'][:-1], 'attention_mask' : decoder_data['attention_mask'][:-1]}\n",
        "  decoder_input_ids = np.array(decoder_data['input_ids']).reshape(1,-1)\n",
        "  decoder_attention_mask = np.array(decoder_data['attention_mask']).reshape(1,-1)\n",
        "\n",
        "  for i in range(MAX_LENGTH):\n",
        "    predictions = model.predict([input_ids, attention_mask, decoder_input_ids, decoder_attention_mask])\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[:, -1:, :]#.reshape(-1)\n",
        "    predicted_id = np.argmax(predictions, axis=-1)\n",
        "    # probs = temperature(logits=predictions, temperature=1.0)\n",
        "    # predicted_id = nucleus(probs=probs, p=0.90)\n",
        "    predicted_id = predicted_id[0][0]\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if predicted_id == 1:\n",
        "      break\n",
        "\n",
        "    # concatenated the predicted_id to the output which is given to the decoder as its input.\n",
        "    decoder_input_ids = np.append(decoder_input_ids.reshape(-1), np.array([predicted_id])).reshape(1,-1)\n",
        "    decoder_attention_mask = np.ones((1, decoder_input_ids.shape[1]))\n",
        "    # print(decoder_input_ids)\n",
        "\n",
        "  return decoder_input_ids\n",
        "\n",
        "def predict(sentence):\n",
        "  prediction = evaluate(sentence)\n",
        "  predicted_sentence = tokenizer.decode([i for i in prediction[0] if i < tokenizer.vocab_size])\n",
        "  return predicted_sentence"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtgzLtwsq2oD"
      },
      "source": [
        "# evaluate()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNmFLqh9q2oD"
      },
      "source": [
        "## Train and Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mvj5TKOGq2oD"
      },
      "source": [
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=160,  # For demonstration, 3 epochs are recommended\n",
        "    verbose=0,\n",
        "    batch_size=33,\n",
        "    validation_split = 0.1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h7xV6XXq2oD"
      },
      "source": [
        "# embedding_model.save_weights('/content/drive/MyDrive/univai/Project/T5_emb_model.h5')"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onqy1u6nq2oE"
      },
      "source": [
        "model.save_weights('/content/drive/MyDrive/univai/Project/T5_univ_man_model.h5')"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNjNOb6z1gy9"
      },
      "source": [
        "predicted_answers = []\n",
        "for i in range(24):\n",
        "  pred_sent = predict([x_eval[0][i], x_eval[1][i]])\n",
        "  predicted_answers.append(pred_sent)\n",
        "  # print(pred_sent)\n",
        "df_dict = {'Questions' : val_questions, 'Answers' : predicted_answers}\n",
        "df = pd.DataFrame(df_dict)\n",
        "df.to_csv('/content/drive/MyDrive/univai/Project/Univ_pred/manual_predicted_T5.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "fWKNOyKuq2oO",
        "outputId": "c67a2984-28dc-462d-a268-d41da7ab3dc4"
      },
      "source": [
        "# df = pd.DataFrame(df_dict)\n",
        "# df.to_csv('/content/drive/MyDrive/univai/Project/Univ_pred/manual_predicted_T5.csv', index=False)\n",
        "df"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Questions</th>\n",
              "      <th>Answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>answer_me: will the pre-class session be recor...</td>\n",
              "      <td>&lt;pad&gt; no. all a a a aa a aa a a a aa a a a a a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>answer_me: what is the deadline for quiz submi...</td>\n",
              "      <td>&lt;pad&gt; 5 pm on thea 5 pm on the a a a homework.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>answer_me: what is the deadline for exercise s...</td>\n",
              "      <td>&lt;pad&gt; 5 pm on thea homework.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>answer_me: how many hours do i need to complet...</td>\n",
              "      <td>&lt;pad&gt; about 15 hours per week.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>answer_me: who will grade the exercise?</td>\n",
              "      <td>&lt;pad&gt; unfortunately, you and your a your a exe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>answer_me: why is the auto-grader failing me?</td>\n",
              "      <td>&lt;pad&gt; unfortunately, you not begrader is not b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>answer_me: do i do the exercises individually?</td>\n",
              "      <td>&lt;pad&gt; individually but you and your peers will...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>answer_me: is the lab compulsory?</td>\n",
              "      <td>&lt;pad&gt; lab.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>answer_me: will the sessions be recorded?</td>\n",
              "      <td>&lt;pad&gt; yes, a a yes, ai yes, ai yes, a homework...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>answer_me: can i have access to the recorded v...</td>\n",
              "      <td>&lt;pad&gt; yes. all a a yes, a yes, a yes, a a a a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>answer_me: where are the recordings?</td>\n",
              "      <td>&lt;pad&gt; yes. all a a a yes, a a a a a a a a a a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>answer_me: where can i ask questions regarding...</td>\n",
              "      <td>&lt;pad&gt; edstem.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>answer_me: where to find course material?</td>\n",
              "      <td>&lt;pad&gt; edstem.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>answer_me: do we have homework?</td>\n",
              "      <td>&lt;pad&gt; yes. each session.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>answer_me: where can i find the homework?</td>\n",
              "      <td>&lt;pad&gt; yes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>answer_me: where to submit the homework?</td>\n",
              "      <td>&lt;pad&gt; yes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>answer_me: where do i find the homework?</td>\n",
              "      <td>&lt;pad&gt; yes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>answer_me: where do i submit my homework assig...</td>\n",
              "      <td>&lt;pad&gt; yes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>answer_me: will the professor take office hours?</td>\n",
              "      <td>&lt;pad&gt; no, your a a a aa aa significant part of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>answer_me: what is the oh zoom link?</td>\n",
              "      <td>&lt;pad&gt; no.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>answer_me: what will we do in projects?</td>\n",
              "      <td>&lt;pad&gt; a a a a a a a a a a a a a a aa significa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>answer_me: what should be the duration of the ...</td>\n",
              "      <td>&lt;pad&gt; yes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>answer_me: do i need to submit the project in ...</td>\n",
              "      <td>&lt;pad&gt; yes.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>answer_me: does attendance count to grading?</td>\n",
              "      <td>&lt;pad&gt; a a a a a a a a a a a a a a a a a a a a ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Questions                                            Answers\n",
              "0   answer_me: will the pre-class session be recor...  <pad> no. all a a a aa a aa a a a aa a a a a a...\n",
              "1   answer_me: what is the deadline for quiz submi...     <pad> 5 pm on thea 5 pm on the a a a homework.\n",
              "2   answer_me: what is the deadline for exercise s...                       <pad> 5 pm on thea homework.\n",
              "3   answer_me: how many hours do i need to complet...                     <pad> about 15 hours per week.\n",
              "4             answer_me: who will grade the exercise?  <pad> unfortunately, you and your a your a exe...\n",
              "5       answer_me: why is the auto-grader failing me?  <pad> unfortunately, you not begrader is not b...\n",
              "6      answer_me: do i do the exercises individually?  <pad> individually but you and your peers will...\n",
              "7                   answer_me: is the lab compulsory?                                         <pad> lab.\n",
              "8           answer_me: will the sessions be recorded?  <pad> yes, a a yes, ai yes, ai yes, a homework...\n",
              "9   answer_me: can i have access to the recorded v...  <pad> yes. all a a yes, a yes, a yes, a a a a ...\n",
              "10               answer_me: where are the recordings?  <pad> yes. all a a a yes, a a a a a a a a a a ...\n",
              "11  answer_me: where can i ask questions regarding...                                      <pad> edstem.\n",
              "12          answer_me: where to find course material?                                      <pad> edstem.\n",
              "13                    answer_me: do we have homework?                           <pad> yes. each session.\n",
              "14          answer_me: where can i find the homework?                                         <pad> yes.\n",
              "15           answer_me: where to submit the homework?                                         <pad> yes.\n",
              "16           answer_me: where do i find the homework?                                         <pad> yes.\n",
              "17  answer_me: where do i submit my homework assig...                                         <pad> yes.\n",
              "18   answer_me: will the professor take office hours?  <pad> no, your a a a aa aa significant part of...\n",
              "19               answer_me: what is the oh zoom link?                                          <pad> no.\n",
              "20            answer_me: what will we do in projects?  <pad> a a a a a a a a a a a a a a aa significa...\n",
              "21  answer_me: what should be the duration of the ...                                         <pad> yes.\n",
              "22  answer_me: do i need to submit the project in ...                                         <pad> yes.\n",
              "23       answer_me: does attendance count to grading?  <pad> a a a a a a a a a a a a a a a a a a a a ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3xBo646J_eB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}