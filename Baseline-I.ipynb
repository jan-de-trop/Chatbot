{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MyBaseline6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ2WxVPn06oG"
      },
      "source": [
        "import json\n",
        "import re\n",
        "import os\n",
        "import zipfile\n",
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import urllib.request\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from tensorflow.keras.layers import dot\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, SimpleRNN, Embedding, Dense, Reshape, LSTM, GRU, Dropout, Bidirectional, BatchNormalization, Flatten\n",
        "from tensorflow.keras.preprocessing.sequence import skipgrams\n",
        "from collections import Counter\n",
        "from operator import itemgetter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuwTmX6pAlTi",
        "outputId": "2bc262aa-d33d-4b3a-f030-30e19d12c8e6"
      },
      "source": [
        "# set path with magic\n",
        "%env DATA_DIR=./data/squad \n",
        "\n",
        "# download the data\n",
        "def download_squad(version=1):\n",
        "    if version == 1:\n",
        "        !wget -P $DATA_DIR https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\n",
        "        !wget -P $DATA_DIR https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\n",
        "    else:\n",
        "        !wget -P $DATA_DIR https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
        "        !wget -P $DATA_DIR https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
        "            \n",
        "download_squad(version=2)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: DATA_DIR=./data/squad\n",
            "--2021-05-30 04:59:04--  https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42123633 (40M) [application/json]\n",
            "Saving to: ‘./data/squad/train-v2.0.json’\n",
            "\n",
            "train-v2.0.json     100%[===================>]  40.17M   119MB/s    in 0.3s    \n",
            "\n",
            "2021-05-30 04:59:06 (119 MB/s) - ‘./data/squad/train-v2.0.json’ saved [42123633/42123633]\n",
            "\n",
            "--2021-05-30 04:59:06--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.108.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4370528 (4.2M) [application/json]\n",
            "Saving to: ‘./data/squad/dev-v2.0.json’\n",
            "\n",
            "dev-v2.0.json       100%[===================>]   4.17M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-05-30 04:59:06 (39.8 MB/s) - ‘./data/squad/dev-v2.0.json’ saved [4370528/4370528]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Kji07lM1QdY",
        "outputId": "95bd3775-9106-42a2-a9d2-55bacc9ece84"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-sJeZUHIzc_"
      },
      "source": [
        "def get_dataframe(file):\n",
        "  f = open(file, 'r')\n",
        "  #loading json file \n",
        "  data = json.loads(f.read())\n",
        "  #creating empty lists to store df values \n",
        "  iid = []\n",
        "  tit = []\n",
        "  con = []\n",
        "  que = []\n",
        "  ans = []\n",
        "  txt = []\n",
        "  #root tags contains 'title' tag and 'paragraphs' list \n",
        "  for i in range(len(data['data'])):\n",
        "    title = data['data'][i]['title']\n",
        "    #'paragraphs' list contains 'context' tag and 'qas' list \n",
        "    for p in range(len(data['data'][i]['paragraphs'])):\n",
        "      context = data['data'][i]['paragraphs'][p]['context']\n",
        "      for q in range(len(data['data'][i]['paragraphs'][p]['qas'])):\n",
        "        # 'qas'list contains 'question', 'Id' tag and 'answers' list \n",
        "        question = data['data'][i]['paragraphs'][p]['qas'][q]['question']\n",
        "        id = data['data'][i]['paragraphs'][p]['qas'][q]['id']\n",
        "        #'answers' list contains 'answer_start' and 'text' tag \n",
        "        for a in range(len(data['data'][i]['paragraphs'][p]['qas'][q]['answers'])):\n",
        "          ans_start = data['data'][i]['paragraphs'][p]['qas'][q]['answers'][a]['answer_start']\n",
        "          text = data['data'][i]['paragraphs'][p]['qas'][q]['answers'][a]['text']\n",
        "          \n",
        "          #appending values to list \n",
        "          iid.append(id)\n",
        "          tit.append(title)\n",
        "          con.append(context)\n",
        "          que.append(question)\n",
        "          ans.append(ans_start)\n",
        "          txt.append(text)\n",
        "  #creating dataframe from lists \n",
        "  new_df = pd.DataFrame(columns=['Id', 'title', 'context', 'question', 'ans_start', 'text'])\n",
        "  new_df.Id = iid\n",
        "  new_df.title=tit\n",
        "  new_df.context = con\n",
        "  new_df.question = que\n",
        "  new_df.ans_start = ans \n",
        "  new_df.text = txt \n",
        "  #removing duplicate columns \n",
        "  final_df = new_df.drop_duplicates(keep='first')\n",
        "\n",
        "  return final_df"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4xcgzSYA4op"
      },
      "source": [
        "# Get SQuAD training set\n",
        "df = get_dataframe('/content/data/squad/dev-v2.0.json')"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daL7viN1QUIA"
      },
      "source": [
        "# Get training data from Univ.AI\n",
        "df_faq = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/UNIV-AI-AI3/faq.csv')"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGBYCRZysSxl"
      },
      "source": [
        "# Concatenate question and answer\n",
        "df['qa_pair'] = df['question'] + ' ' + df['text']\n",
        "df_faq['qa_pair'] = df_faq['Question'] + ' ' + df_faq['Answer']"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44fDC5TC4qsd"
      },
      "source": [
        "def clean_data(data, col_name): \n",
        "    data[col_name] = [re.sub(\"[^a-zA-Z ]\", \"\", i) for i in data[col_name]]\n",
        "    data = data.applymap(lambda s:s.lower() if type(s) == str else s)\n",
        "    l = [i for i in data.qa_pair if len(i.split(\" \"))>5 and len(i.split(\" \"))<=55]\n",
        "    data = pd.DataFrame(l, columns=[col_name])\n",
        "    data[col_name] = '<s> '+data[col_name] + ' </s>'\n",
        "    return data"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXr8_gan4_Mr"
      },
      "source": [
        "# Clean data\n",
        "df = clean_data(df, 'qa_pair')\n",
        "df_faq = clean_data(df_faq, 'qa_pair')"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I4mZvEpSipw"
      },
      "source": [
        "# Concatenate SQuAD and Univ.AI training data\n",
        "df_joint = pd.concat([df, df_faq])"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okAybikx8bee"
      },
      "source": [
        "# Size of the vocabulary\n",
        "vocab_size = 5000 \n",
        "\n",
        "# Tokenize the data\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=vocab_size, lower=True, char_level=False, split=' ', oov_token=None, filters='!\"#$%&()*+,-.:;=?@[\\\\]^_`{|}~\\t\\n')"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDe9oz8V8bnb"
      },
      "source": [
        "# Fit the tokenizer on text\n",
        "tokenizer.fit_on_texts(df_joint.qa_pair)\n",
        "\n",
        "# Text to sequence\n",
        "data = tokenizer.texts_to_sequences(df.qa_pair)\n",
        "data_faq = tokenizer.texts_to_sequences(df_faq.qa_pair)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnpOKTD99ia9"
      },
      "source": [
        "x_data = [i[:-1] for i in data]\n",
        "y_data = [i[1:] for i in data]\n",
        "\n",
        "x_data_faq = [i[:-1] for i in data]\n",
        "y_data_faq = [i[1:] for i in data]\n",
        "\n",
        "# Post-pad input and output (max length is 55)\n",
        "x_data = tf.convert_to_tensor(sequence.pad_sequences(x_data, padding='post', maxlen=55))\n",
        "y_data = tf.convert_to_tensor(sequence.pad_sequences(y_data, padding='post', maxlen=55))\n",
        "\n",
        "x_data_faq = tf.convert_to_tensor(sequence.pad_sequences(x_data_faq, padding='post', maxlen=55))\n",
        "y_data_faq = tf.convert_to_tensor(sequence.pad_sequences(y_data_faq, padding='post', maxlen=55))"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwxe4EDN9pI0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3fa8c46-7858-4222-c354-604f964923b2"
      },
      "source": [
        "# Simple RNN model\n",
        "\n",
        "hidden_size = 300\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "inputs = Input(shape=x_data.shape[1:], name='input')\n",
        "x = Embedding(input_dim=vocab_size+1, output_dim=hidden_size, name=\"embedding\", mask_zero=True)(inputs)\n",
        "x = tf.keras.layers.SimpleRNN(hidden_size, return_sequences=True, name=\"RNN_layer_1\")(x)\n",
        "x = tf.keras.layers.SimpleRNN(hidden_size, return_sequences=True, name=\"RNN_layer_2\")(x)\n",
        "outputs = Dense(vocab_size, activation='softmax')(x)\n",
        "model = Model(inputs=inputs, outputs=outputs, name=\"Simple_RNN_model\")\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Simple_RNN_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 55)]              0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 55, 300)           1500300   \n",
            "_________________________________________________________________\n",
            "RNN_layer_1 (SimpleRNN)      (None, 55, 300)           180300    \n",
            "_________________________________________________________________\n",
            "RNN_layer_2 (SimpleRNN)      (None, 55, 300)           180300    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 55, 5000)          1505000   \n",
            "=================================================================\n",
            "Total params: 3,365,900\n",
            "Trainable params: 3,365,900\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhD6yZwUXKgg"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(1e-2), metrics='accuracy')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rjz5nqz49tbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5e990ad-ad92-4120-abbf-2b84b5618437"
      },
      "source": [
        "history = model.fit(x_data, y_data, epochs=50, batch_size=512, validation_split=0.2)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "17/17 [==============================] - 10s 340ms/step - loss: 1.7128 - accuracy: 0.1075 - val_loss: 1.7644 - val_accuracy: 0.1482\n",
            "Epoch 2/50\n",
            "17/17 [==============================] - 5s 315ms/step - loss: 1.5985 - accuracy: 0.1514 - val_loss: 1.7534 - val_accuracy: 0.1540\n",
            "Epoch 3/50\n",
            "17/17 [==============================] - 5s 314ms/step - loss: 1.5675 - accuracy: 0.1695 - val_loss: 1.7378 - val_accuracy: 0.1698\n",
            "Epoch 4/50\n",
            "17/17 [==============================] - 5s 309ms/step - loss: 1.5302 - accuracy: 0.1875 - val_loss: 1.6920 - val_accuracy: 0.1858\n",
            "Epoch 5/50\n",
            "17/17 [==============================] - 5s 321ms/step - loss: 1.4814 - accuracy: 0.2042 - val_loss: 1.6811 - val_accuracy: 0.1836\n",
            "Epoch 6/50\n",
            "17/17 [==============================] - 5s 314ms/step - loss: 1.4290 - accuracy: 0.2139 - val_loss: 1.6968 - val_accuracy: 0.1878\n",
            "Epoch 7/50\n",
            "17/17 [==============================] - 5s 315ms/step - loss: 1.3793 - accuracy: 0.2232 - val_loss: 1.6982 - val_accuracy: 0.1938\n",
            "Epoch 8/50\n",
            "17/17 [==============================] - 5s 308ms/step - loss: 1.3281 - accuracy: 0.2353 - val_loss: 1.7105 - val_accuracy: 0.1940\n",
            "Epoch 9/50\n",
            "17/17 [==============================] - 5s 316ms/step - loss: 1.2800 - accuracy: 0.2429 - val_loss: 1.7200 - val_accuracy: 0.1997\n",
            "Epoch 10/50\n",
            "17/17 [==============================] - 5s 311ms/step - loss: 1.2354 - accuracy: 0.2512 - val_loss: 1.7430 - val_accuracy: 0.1978\n",
            "Epoch 11/50\n",
            "17/17 [==============================] - 5s 322ms/step - loss: 1.1925 - accuracy: 0.2602 - val_loss: 1.7431 - val_accuracy: 0.1894\n",
            "Epoch 12/50\n",
            "17/17 [==============================] - 5s 317ms/step - loss: 1.1610 - accuracy: 0.2643 - val_loss: 1.7446 - val_accuracy: 0.1936\n",
            "Epoch 13/50\n",
            "17/17 [==============================] - 5s 320ms/step - loss: 1.1161 - accuracy: 0.2771 - val_loss: 1.7626 - val_accuracy: 0.1935\n",
            "Epoch 14/50\n",
            "17/17 [==============================] - 5s 314ms/step - loss: 1.0760 - accuracy: 0.2886 - val_loss: 1.7892 - val_accuracy: 0.1926\n",
            "Epoch 15/50\n",
            "17/17 [==============================] - 5s 316ms/step - loss: 1.0427 - accuracy: 0.2976 - val_loss: 1.8231 - val_accuracy: 0.1891\n",
            "Epoch 16/50\n",
            "17/17 [==============================] - 5s 312ms/step - loss: 1.0113 - accuracy: 0.3102 - val_loss: 1.8473 - val_accuracy: 0.1924\n",
            "Epoch 17/50\n",
            "17/17 [==============================] - 5s 313ms/step - loss: 0.9731 - accuracy: 0.3221 - val_loss: 1.8458 - val_accuracy: 0.1862\n",
            "Epoch 18/50\n",
            "17/17 [==============================] - 5s 313ms/step - loss: 0.9369 - accuracy: 0.3368 - val_loss: 1.8521 - val_accuracy: 0.1907\n",
            "Epoch 19/50\n",
            "17/17 [==============================] - 5s 316ms/step - loss: 0.9055 - accuracy: 0.3497 - val_loss: 1.8724 - val_accuracy: 0.1856\n",
            "Epoch 20/50\n",
            "17/17 [==============================] - 5s 313ms/step - loss: 0.8732 - accuracy: 0.3655 - val_loss: 1.9033 - val_accuracy: 0.1849\n",
            "Epoch 21/50\n",
            "17/17 [==============================] - 5s 316ms/step - loss: 0.8429 - accuracy: 0.3799 - val_loss: 1.9276 - val_accuracy: 0.1863\n",
            "Epoch 22/50\n",
            "17/17 [==============================] - 5s 320ms/step - loss: 0.8143 - accuracy: 0.3922 - val_loss: 1.9518 - val_accuracy: 0.1729\n",
            "Epoch 23/50\n",
            "17/17 [==============================] - 5s 319ms/step - loss: 0.7971 - accuracy: 0.4006 - val_loss: 1.9659 - val_accuracy: 0.1827\n",
            "Epoch 24/50\n",
            "17/17 [==============================] - 5s 313ms/step - loss: 0.7639 - accuracy: 0.4194 - val_loss: 1.9807 - val_accuracy: 0.1820\n",
            "Epoch 25/50\n",
            "17/17 [==============================] - 5s 320ms/step - loss: 0.7410 - accuracy: 0.4333 - val_loss: 2.0080 - val_accuracy: 0.1826\n",
            "Epoch 26/50\n",
            "17/17 [==============================] - 5s 318ms/step - loss: 0.7103 - accuracy: 0.4512 - val_loss: 2.0221 - val_accuracy: 0.1792\n",
            "Epoch 27/50\n",
            "17/17 [==============================] - 5s 316ms/step - loss: 0.6842 - accuracy: 0.4670 - val_loss: 2.0453 - val_accuracy: 0.1705\n",
            "Epoch 28/50\n",
            "17/17 [==============================] - 5s 312ms/step - loss: 0.6624 - accuracy: 0.4794 - val_loss: 2.0663 - val_accuracy: 0.1764\n",
            "Epoch 29/50\n",
            "17/17 [==============================] - 5s 311ms/step - loss: 0.6416 - accuracy: 0.4921 - val_loss: 2.0759 - val_accuracy: 0.1776\n",
            "Epoch 30/50\n",
            "17/17 [==============================] - 5s 312ms/step - loss: 0.6210 - accuracy: 0.5066 - val_loss: 2.1064 - val_accuracy: 0.1756\n",
            "Epoch 31/50\n",
            "17/17 [==============================] - 5s 313ms/step - loss: 0.6057 - accuracy: 0.5164 - val_loss: 2.1162 - val_accuracy: 0.1731\n",
            "Epoch 32/50\n",
            "17/17 [==============================] - 5s 314ms/step - loss: 0.5889 - accuracy: 0.5260 - val_loss: 2.1363 - val_accuracy: 0.1692\n",
            "Epoch 33/50\n",
            "17/17 [==============================] - 5s 307ms/step - loss: 0.5751 - accuracy: 0.5356 - val_loss: 2.1465 - val_accuracy: 0.1748\n",
            "Epoch 34/50\n",
            "17/17 [==============================] - 5s 310ms/step - loss: 0.5585 - accuracy: 0.5459 - val_loss: 2.1724 - val_accuracy: 0.1718\n",
            "Epoch 35/50\n",
            "17/17 [==============================] - 5s 316ms/step - loss: 0.5479 - accuracy: 0.5523 - val_loss: 2.1833 - val_accuracy: 0.1710\n",
            "Epoch 36/50\n",
            "17/17 [==============================] - 5s 317ms/step - loss: 0.5340 - accuracy: 0.5632 - val_loss: 2.2081 - val_accuracy: 0.1744\n",
            "Epoch 37/50\n",
            "17/17 [==============================] - 5s 317ms/step - loss: 0.5195 - accuracy: 0.5723 - val_loss: 2.2077 - val_accuracy: 0.1696\n",
            "Epoch 38/50\n",
            "17/17 [==============================] - 5s 315ms/step - loss: 0.5087 - accuracy: 0.5791 - val_loss: 2.2357 - val_accuracy: 0.1638\n",
            "Epoch 39/50\n",
            "17/17 [==============================] - 6s 324ms/step - loss: 0.5001 - accuracy: 0.5852 - val_loss: 2.2589 - val_accuracy: 0.1667\n",
            "Epoch 40/50\n",
            "17/17 [==============================] - 5s 316ms/step - loss: 0.4907 - accuracy: 0.5918 - val_loss: 2.2616 - val_accuracy: 0.1693\n",
            "Epoch 41/50\n",
            "17/17 [==============================] - 5s 313ms/step - loss: 0.4816 - accuracy: 0.5964 - val_loss: 2.2716 - val_accuracy: 0.1692\n",
            "Epoch 42/50\n",
            "17/17 [==============================] - 5s 313ms/step - loss: 0.4670 - accuracy: 0.6085 - val_loss: 2.2937 - val_accuracy: 0.1686\n",
            "Epoch 43/50\n",
            "17/17 [==============================] - 5s 311ms/step - loss: 0.4572 - accuracy: 0.6170 - val_loss: 2.2992 - val_accuracy: 0.1692\n",
            "Epoch 44/50\n",
            "17/17 [==============================] - 5s 321ms/step - loss: 0.4524 - accuracy: 0.6185 - val_loss: 2.3219 - val_accuracy: 0.1656\n",
            "Epoch 45/50\n",
            "17/17 [==============================] - 5s 310ms/step - loss: 0.4481 - accuracy: 0.6206 - val_loss: 2.3299 - val_accuracy: 0.1673\n",
            "Epoch 46/50\n",
            "17/17 [==============================] - 5s 316ms/step - loss: 0.4370 - accuracy: 0.6281 - val_loss: 2.3362 - val_accuracy: 0.1613\n",
            "Epoch 47/50\n",
            "17/17 [==============================] - 5s 315ms/step - loss: 0.4336 - accuracy: 0.6309 - val_loss: 2.3525 - val_accuracy: 0.1627\n",
            "Epoch 48/50\n",
            "17/17 [==============================] - 5s 310ms/step - loss: 0.4241 - accuracy: 0.6381 - val_loss: 2.3670 - val_accuracy: 0.1631\n",
            "Epoch 49/50\n",
            "17/17 [==============================] - 5s 315ms/step - loss: 0.4144 - accuracy: 0.6465 - val_loss: 2.3888 - val_accuracy: 0.1599\n",
            "Epoch 50/50\n",
            "17/17 [==============================] - 5s 318ms/step - loss: 0.4080 - accuracy: 0.6500 - val_loss: 2.3870 - val_accuracy: 0.1661\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGHtVRX9CBsK"
      },
      "source": [
        "# Save/load weights\n",
        "model.load_weights('/content/drive/My Drive/Colab Notebooks/UNIV-AI-AI3/model_weights_1.h5')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQJdK3mPDrGu",
        "outputId": "657b2b7d-7641-4cb8-c411-afb990330dab"
      },
      "source": [
        "# Output single prediction\n",
        "output = outputs[:,-1,:]\n",
        "model_pred = Model(inputs, outputs=output)\n",
        "model_pred.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 55)]              0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 55, 300)           1500300   \n",
            "_________________________________________________________________\n",
            "RNN_layer_1 (SimpleRNN)      (None, 55, 300)           180300    \n",
            "_________________________________________________________________\n",
            "RNN_layer_2 (SimpleRNN)      (None, 55, 300)           180300    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 55, 5000)          1505000   \n",
            "_________________________________________________________________\n",
            "tf.__operators__.getitem_1 ( (None, 5000)              0         \n",
            "=================================================================\n",
            "Total params: 3,365,900\n",
            "Trainable params: 3,365,900\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23tnGl5rEINg"
      },
      "source": [
        "df_test = pd.read_csv('/content/drive/My Drive/Colab Notebooks/UNIV-AI-AI3/test.csv')"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljS1XJYMFJ4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "030af42c-cf3c-4636-9804-0afdf183ae16"
      },
      "source": [
        "for test_num in range(len(df_test)-1):\n",
        "\n",
        "  i = 0\n",
        "  predicted_word = \"\"\n",
        "  input = df_test.Questions[test_num].lower()\n",
        "\n",
        "  # Predict next 10 words or until the </s> token\n",
        "  while i<10 or predicted_word!=\"</s>\":\n",
        "    test_data = '<s> '+input+' </s>'\n",
        "    test_data = tokenizer.texts_to_sequences([test_data])\n",
        "    test_data[0] = test_data[0][:-1] \n",
        "    test_data = np.array(test_data)\n",
        "    test_data = sequence.pad_sequences(test_data, padding='post',maxlen=55)\n",
        "    pred = model_pred([test_data])\n",
        "    index = pred[0].numpy().argmax()\n",
        "    character = tokenizer.sequences_to_texts([[index]])\n",
        "    predicted_word = character[0]\n",
        "    input = input+\" \"+ predicted_word\n",
        "    i+=1\n",
        "\n",
        "  print(\"Question:\", df_test.Questions[test_num])\n",
        "  print(\"Answer:\", input[len(df_test.Questions[test_num]):])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question: Will the pre-class session be recorded?\n",
            "Answer:  in the university decide to get rid of the football program emphasize academics </s>\n",
            "Question: What is the deadline for quiz submission?\n",
            "Answer:  plague spreading to the individual </s> </s> </s> </s> </s>\n",
            "Question: What is the deadline for exercise submission?\n",
            "Answer:  were to a higher energy content </s> </s> </s> </s>\n",
            "Question: How many hours do I need to complete this course?\n",
            "Answer:  like responses </s> </s> </s> </s> </s> </s> </s> </s>\n",
            "Question: Who will grade the exercise?\n",
            "Answer:  treaty the concept of human capital formation long </s> </s>\n",
            "Question: Why is the auto-grader failing me?\n",
            "Answer:  with huguenots foreign </s> </s> </s> </s> </s> </s> </s>\n",
            "Question: Do I do the exercises individually?\n",
            "Answer:  in farming lead to the black death </s> </s> </s>\n",
            "Question: Is the lab compulsory?\n",
            "Answer:  in scotland </s> </s> </s> </s> </s> </s> </s> </s>\n",
            "Question: Will the sessions be recorded?\n",
            "Answer:  in the amazon basin moist tropical vegetation cover </s> </s>\n",
            "Question: Can I have access to the recorded videos?\n",
            "Answer:  to do what plan the last frontier foundation </s> </s>\n",
            "Question: Where are the recordings?\n",
            "Answer:  gonads located in the s </s> </s> </s> </s> </s>\n",
            "Question: Where can I ask questions regarding reading material\n",
            "Answer:  has to one of their services in question floor </s>\n",
            "Question: Where to find course material?\n",
            "Answer:  utility version of the rhine </s> in </s> </s> </s>\n",
            "Question: Do we have homework?\n",
            "Answer:  about civil disobedience civil disobedience is only justified against governmental entities </s>\n",
            "Question: Where can I find the homework?\n",
            "Answer:  of the horizontal engine corliss </s> </s> </s> </s> </s>\n",
            "Question: Where to submit the homework?\n",
            "Answer:  origin about civil disobedience criminal investigations </s> </s> </s> </s>\n",
            "Question: Where do I find the homework?\n",
            "Answer:  of the horizontal engine corliss </s> </s> </s> </s> </s>\n",
            "Question: Where do I submit my homework assignment?\n",
            "Answer:  that people have to do to help preserve societys tolerance of civil disobedience </s>\n",
            "Question: Will the professor take office hours?\n",
            "Answer:  </s> in </s> </s> </s> </s> </s> </s> </s> </s>\n",
            "Question: What is the OH zoom link?\n",
            "Answer:  reason pharmacists can provide for the design and the public of member states </s>\n",
            "Question: What will we do in projects?\n",
            "Answer:  inequality in what country russia </s> and khitans </s> </s>\n",
            "Question: What should be the duration of the presentation video?\n",
            "Answer:  in </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
            "Question: Do I need to submit the project in a group?\n",
            "Answer:  </s> due to what the convecting mantle </s> </s> </s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7ipeBjZq2Vv",
        "outputId": "46072563-2d49-4d50-af08-2fbb0bb375c8"
      },
      "source": [
        "model.trainable = False\n",
        "\n",
        "inputs = Input(shape=x_data.shape[1:], name='input')\n",
        "x = model(inputs, training=False)\n",
        "x = tf.keras.layers.SimpleRNN(hidden_size, return_sequences=True, name=\"RNN_layer_3\")(x)\n",
        "x = tf.keras.layers.SimpleRNN(hidden_size, return_sequences=True, name=\"RNN_layer_4\")(x)\n",
        "outputs = Dense(vocab_size, activation='softmax')(x)\n",
        "model2 = Model(inputs=inputs, outputs=outputs, name=\"Simple_RNN_model_2\")\n",
        "model2.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Simple_RNN_model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 55)]              0         \n",
            "_________________________________________________________________\n",
            "Simple_RNN_model (Functional (None, 55, 5000)          3365900   \n",
            "_________________________________________________________________\n",
            "RNN_layer_3 (SimpleRNN)      (None, 55, 300)           1590300   \n",
            "_________________________________________________________________\n",
            "RNN_layer_4 (SimpleRNN)      (None, 55, 300)           180300    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 55, 5000)          1505000   \n",
            "=================================================================\n",
            "Total params: 6,641,500\n",
            "Trainable params: 3,275,600\n",
            "Non-trainable params: 3,365,900\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0kdt3b4uVlY"
      },
      "source": [
        "model2.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(1e-2), metrics='accuracy')"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1G1sNj1owpuN"
      },
      "source": [
        "history = model2.fit(x_data_faq, y_data_faq, epochs=50, batch_size=512, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHEmSz3Qyekt"
      },
      "source": [
        "# Save/load weights\n",
        "model.load_weights('/content/drive/My Drive/Colab Notebooks/UNIV-AI-AI3/model_weights_4.h5')"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhbdCzNZxcQq"
      },
      "source": [
        "# Output single prediction\n",
        "output = outputs[:,-1,:]\n",
        "model_pred2 = Model(inputs, outputs=output)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtEUcnXYwt10",
        "outputId": "f1c16328-a159-420b-fd8f-903bd4f723ba"
      },
      "source": [
        "for test_num in range(len(df_test)-1):\n",
        "\n",
        "  i = 0\n",
        "  predicted_word = \"\"\n",
        "  input = df_test.Questions[test_num].lower()\n",
        "\n",
        "  # Predict next 10 words or until the </s> token\n",
        "  while i<10 or predicted_word!=\"</s>\":\n",
        "    test_data = '<s> '+input+' </s>'\n",
        "    test_data = tokenizer.texts_to_sequences([test_data])\n",
        "    test_data[0] = test_data[0][:-1] \n",
        "    test_data = np.array(test_data)\n",
        "    test_data = sequence.pad_sequences(test_data, padding='post',maxlen=55)\n",
        "    pred = model_pred2([test_data])\n",
        "    index = pred[0].numpy().argmax()\n",
        "    character = tokenizer.sequences_to_texts([[index]])\n",
        "    predicted_word = character[0]\n",
        "    input = input+\" \"+ predicted_word\n",
        "    i+=1\n",
        "\n",
        "  print(\"Question:\", df_test.Questions[test_num])\n",
        "  print(\"Answer:\", input[len(df_test.Questions[test_num]):])"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question: Will the pre-class session be recorded?\n",
            "Answer:  the the the </s> </s> </s> </s> </s> </s> </s>\n",
            "Question: What is the deadline for quiz submission?\n",
            "Answer:  the the the the </s> </s> </s> </s> </s> </s>\n",
            "Question: What is the deadline for exercise submission?\n",
            "Answer:  the the the </s> </s> </s> </s> </s> </s> </s>\n",
            "Question: How many hours do I need to complete this course?\n",
            "Answer:  </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
            "Question: Who will grade the exercise?\n",
            "Answer:  the the the the </s> </s> </s> </s> </s> </s>\n",
            "Question: Why is the auto-grader failing me?\n",
            "Answer:  the the the </s> </s> </s> </s> </s> </s> </s>\n",
            "Question: Do I do the exercises individually?\n",
            "Answer:  the the the the </s> </s> </s> </s> </s> </s>\n",
            "Question: Is the lab compulsory?\n",
            "Answer:  of the the the the </s> </s> </s> </s> </s>\n",
            "Question: Will the sessions be recorded?\n",
            "Answer:  of the the the the </s> </s> </s> </s> </s>\n",
            "Question: Can I have access to the recorded videos?\n",
            "Answer:  the the </s> </s> </s> </s> </s> </s> </s> </s>\n",
            "Question: Where are the recordings?\n",
            "Answer:  the of the the the the </s> </s> </s> </s>\n",
            "Question: Where can I ask questions regarding reading material\n",
            "Answer:  the </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
            "Question: Where to find course material?\n",
            "Answer:  the the the the </s> </s> </s> </s> </s> </s>\n",
            "Question: Do we have homework?\n",
            "Answer:  of the the the the </s> </s> </s> </s> </s>\n",
            "Question: Where can I find the homework?\n",
            "Answer:  the the the </s> </s> </s> </s> </s> </s> </s>\n",
            "Question: Where to submit the homework?\n",
            "Answer:  the the the the </s> </s> </s> </s> </s> </s>\n",
            "Question: Where do I find the homework?\n",
            "Answer:  the the the </s> </s> </s> </s> </s> </s> </s>\n",
            "Question: Where do I submit my homework assignment?\n",
            "Answer:  the the the the </s> </s> </s> </s> </s> </s>\n",
            "Question: Will the professor take office hours?\n",
            "Answer:  the the the the </s> </s> </s> </s> </s> </s>\n",
            "Question: What is the OH zoom link?\n",
            "Answer:  of the the the the </s> </s> </s> </s> </s>\n",
            "Question: What will we do in projects?\n",
            "Answer:  the the the </s> </s> </s> </s> </s> </s> </s>\n",
            "Question: What should be the duration of the presentation video?\n",
            "Answer:  the </s> </s> </s> </s> </s> </s> </s> </s> </s>\n",
            "Question: Do I need to submit the project in a group?\n",
            "Answer:  </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttMEQEe-yiwn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}